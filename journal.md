# Thinking & Progress

## Week 1, Jan 23 - Jan 30: 

Created this repo!

Finished the assigned reading: [Causal Inference In Statistics: A Primer](https://www.datascienceassn.org/sites/default/files/CAUSAL%20INFERENCE%20IN%20STATISTICS.pdf). 

Detailed [reading notes](https://www.datascienceassn.org/sites/default/files/CAUSAL%20INFERENCE%20IN%20STATISTICS.pdf) is under /doc folder of this repo.


## Week 2, Jan 31 - Feb 6:

Start thinking about project topics. 

I took IEOR 4575 Reinforcement Learning from Prof. Shipra, as well as COMS 6998 Bandits & Reinforcement Learning from [Prof. Krishnamurthy](https://people.cs.umass.edu/~akshay/) this semester, so I'm very willing to do some projects at the intersection of causal inference and reinforcement learning!

The [Causal Reinforcement Learning (CRL)](https://crl.causalai.net/) website is quite useful, since it summarizes recent advances of CRL according to several tasks pretty systematically. 

(1) I started my reading from the paper [Bandits with Unobsergved Confounders: A Causal Approach (annotated)](https://github.com/HL-hanlin/STAT8100_AppliedCausality/blob/main/etc/Bandits%20with%20Unobserved%20Confounders.pdf), which is probably the paper that intersects causal inference with RL models with unobserved confounders (UC). It showed that when UC exists, current bandit algorithms which try to maximize rewards based on estimation of the experimental distribution, are not always the best to pursue. The greedy casino example in this paper is quite useful for illustration.

(2) To follow up, I read the other paper [Counterfactual Data-Fusion for Online Reinforcement Learning (annotated)](https://github.com/HL-hanlin/STAT8100_AppliedCausality/blob/main/etc/Counterfactual%20Data-Fusion%20for%20Online%20Reinforcement%20Learners.pdf) that could be seen as a generalization of the greedy casino example in the last paper by using counterfactual-based decision making. 




## Week 3, Feb 7 - Feb 13:

