{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[BCINV]_Apr25.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXttaQe-507l","executionInfo":{"status":"ok","timestamp":1651000157082,"user_tz":240,"elapsed":19861,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"b3beec4d-8636-4743-edc4-c520aba71514"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import os\n","\n","import torch\n","os.chdir('/content/drive/MyDrive/ImitationLearning/Invariant-Causal-Imitation-Learning-main/')\n"]},{"cell_type":"markdown","source":["# load"],"metadata":{"id":"CMy2nIGPEiAs"}},{"cell_type":"code","source":["!pip install mpi4py \n","!pip install box2d-py\n","!pip install box2d \n","!pip3 install gym[Box_2D] \n","!pip install gym==0.17.2 -qqq\n","!pip install numpy~=1.18.2 -qqq\n","!pip install pandas~=1.0.4 -qqq\n","!pip install PyYAML~=5.4.1 -qqq\n","!pip install scikit-learn~=0.22.2 -qqq\n","!pip install scipy~=1.1.0 -qqq\n","!pip install stable-baselines~=2.10.1 -qqq\n","!pip install tensorflow~=1.15.0 -qqq\n","!pip install torch>=1.6.0 -qqq\n","!pip install tqdm~=4.32.1 -qqq\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhOh_Fj16Eow","executionInfo":{"status":"ok","timestamp":1651000292636,"user_tz":240,"elapsed":132923,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"c3e64f13-2e38-4a94-8cb1-ff29bd3a58a7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 6.9 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185267 sha256=a7fad3ab07c6625e676d7d07123dfa8ada27a11f3eebd5a887a2cff74feb0864\n","  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.3\n","Collecting box2d-py\n","  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 8.7 MB/s \n","\u001b[?25hInstalling collected packages: box2d-py\n","Successfully installed box2d-py-2.3.8\n","Collecting box2d\n","  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 6.8 MB/s \n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.6)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n","\u001b[K     |████████████████████████████████| 1.6 MB 8.3 MB/s \n","\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 20.1 MB 91.1 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n","jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 10.1 MB 7.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.5 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 636 kB 7.2 MB/s \n","\u001b[K     |████████████████████████████████| 7.1 MB 3.5 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 31.2 MB 98.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 240 kB 6.9 MB/s \n","\u001b[K     |████████████████████████████████| 110.5 MB 1.5 kB/s \n","\u001b[K     |████████████████████████████████| 503 kB 47.1 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 55.3 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 8.8 MB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 52.8 MB/s \n","\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 50 kB 4.6 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.32.2 which is incompatible.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.32.2 which is incompatible.\n","fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.32.2 which is incompatible.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["#config"],"metadata":{"id":"UoOvpQGcfM2h"}},{"cell_type":"code","source":["\n","config = {\n","    \"ENV\": \"CartPole-v1\",\n","    \"ALG\": \"BCIRMStudent_Apr17\",\n","    \"NUM_TRAJS_GIVEN\": 20, #\n","    \"NUM_TRAINING_ENVS\": 2,\n","    \"NOISE_DIM\": 4,\n","    \"REP_SIZE\": 16,\n","    \"TRAJ_SHIFT\": 20, # 20,\n","    \"SAMPLING_RATE\": 5,\n","    \"NUM_STEPS_TRAIN\": 10000,\n","    \"NUM_TRAJS_VALID\": 100,\n","    \"NUM_REPETITIONS\": 15,\n","    \"BATCH_SIZE\": 64,\n","    \"MLP_WIDTHS\": 64,\n","    \"ADAM_ALPHA\": 1e-3,\n","    \"SGLD_BUFFER_SIZE\": 10000,\n","    \"SGLD_LEARN_RATE\": 0.01,\n","    \"SGLD_NOISE_COEF\": 0.01,\n","    \"SGLD_NUM_STEPS\": 100,\n","    \"SGLD_REINIT_FREQ\": 0.05,\n","    \"NUM_STEPS_TRAIN_ENERGY_MODEL\": 1000,\n","    #\"NUM_STEPS_TRAIN_VAE_MODEL\": 20000,\n","    'TRIAL': 0\n","}\n","\n","\n","config['ENV'] = \"LunarLander-v2\"\n","#config['ENV'] = \"CartPole-v1\"\n","\n","#config['METHOD'] = \"BCIRM\"\n","#config['METHOD'] = \"iVAE_IRM\"\n","config['METHOD'] = \"BCINV\"\n","\n","\n","\n","\n","\n","\n","if config['METHOD'] == 'BCIRM':\n","    config['l2_regularizer_weight'] = 0.001\n","    config['penalty_weight'] = 10000\n","    config['penalty_anneal_iters'] = 2500\n","elif config['METHOD'] == \"iVAE_IRM\":\n","    config[\"NUM_STEPS_TRAIN_VAE_MODEL\"] = 20000 # phase1\n","    config[\"NUM_STEPS_TRAIN\"] = 50000 # phase 3\n","    config['PHASE2_SAMPLES'] = 50000 # phase 2\n","    config['l2_regularizer_weight'] = 0.001\n","    config['penalty_weight'] = 10\n","elif config['METHOD'] == \"BCINV\":\n","    pass\n","\n"],"metadata":{"id":"4qkwWpjMfNzN","executionInfo":{"status":"ok","timestamp":1651001072773,"user_tz":240,"elapsed":160,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#testing/il"],"metadata":{"id":"tXRGSCjZfbnX"}},{"cell_type":"code","source":["import argparse\n","import os\n","import pickle\n","\n","import gym\n","import numpy as np\n","import pandas as pd\n","import yaml\n","import numpy as np\n","\n","from testing.paths import get_model_path, get_trajs_path  # pylint: disable=reimported\n","\n","from contrib.env_wrapper import EnvWrapper, get_test_mult_factors\n","from network import EnvDiscriminator\n","from network import FeaturesDecoder\n","from network import FeaturesEncoder\n","from network import ObservationsDecoder\n","from network import StudentNetwork, StudentNetwork_2hidden\n","\n","\n","from student import ICILStudent, BCStudent, BCIRMStudent, iVAE_IRMStudent, BCINVStudent\n","from testing.train_utils import fill_buffer, make_agent, save_results\n","from vae.ivae_wrapper import VAE_wrapper\n","  \n","from torch import nn"],"metadata":{"id":"GqnTIvivg1DT","executionInfo":{"status":"ok","timestamp":1651001111292,"user_tz":240,"elapsed":10553,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7b8a8f8-6451-43b2-f035-72b4fdf73cb1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n","  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"]}]},{"cell_type":"markdown","source":["# make student"],"metadata":{"id":"hsMME-Bm3oMT"}},{"cell_type":"code","source":["\n","\n","# pylint: disable=redefined-outer-name\n","def make_student(run_seed, config):\n","    env = gym.make(config[\"ENV\"])\n","    trajs_path = get_trajs_path(config[\"ENV\"], \"student_\" + config[\"ALG\"], env_id=\"student\", run_seed=run_seed)\n","    model_path = get_model_path(config[\"ENV\"], \"student_\" + config[\"ALG\"], run_seed=run_seed)\n","\n","    state_dim = env.observation_space.shape[0] + config[\"NOISE_DIM\"]\n","    action_dim = env.action_space.n\n","    num_training_envs = config[\"NUM_TRAINING_ENVS\"]\n","\n","    # run_seed = run_seed\n","    batch_size = config[\"BATCH_SIZE\"]\n","    teacher = make_agent(config[\"ENV\"], config[\"EXPERT_ALG\"], config[\"NUM_TRAINING_ENVS\"])\n","    teacher.load_pretrained()\n","\n","    buffer = fill_buffer(\n","        trajs_path=teacher.trajs_paths,\n","        batch_size=batch_size,\n","        run_seed=run_seed,\n","        traj_shift=config[\"TRAJ_SHIFT\"],\n","        buffer_size_in_trajs=config[\"NUM_TRAJS_GIVEN\"],\n","        sampling_rate=config[\"SAMPLING_RATE\"],\n","    )\n","\n","    if buffer.total_size < batch_size:\n","        batch_size = buffer.total_size\n","\n","\n","\n","    ##########################      COMMON      ##########################\n","\n","    print(\"state_dim\", state_dim)\n","\n","    causal_features_encoder = FeaturesEncoder(\n","        input_size=state_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"]\n","    )\n","\n","    policy_network = StudentNetwork(in_dim=config[\"REP_SIZE\"], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","\n","    #print(\"config method = \", config['METHOD'])\n","\n","\n","    ##########################       BC       #######################\n","\n","    if config['METHOD'] == 'BC':\n","\n","        #causal_features_encoder = FeaturesEncoder(\n","        #    input_size=state_dim-4, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"]\n","        #)\n","\n","        return BCStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","    ##########################       BC IRM       #######################\n","\n","\n","    elif config['METHOD'] == 'BCIRM':\n","\n","        return BCIRMStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","\n","    ##########################       BC INV       #######################\n","\n","\n","    elif config['METHOD'] == 'BCINV':\n","\n","        env_discriminator = EnvDiscriminator(representation_size=config[\"REP_SIZE\"], num_envs=config[\"NUM_TRAINING_ENVS\"], width=config[\"MLP_WIDTHS\"])\n","\n","        return BCINVStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            env_discriminator = env_discriminator,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","    ##########################       iVAE IRM       #######################\n","\n","    elif config['METHOD'] == 'iVAE_IRM':\n","\n","        config['LATENT_DIM'] = state_dim - 4  # latent dim for iVAE, not causal-feature-encoder and policy-network\n","\n","        vae_wrapper =  VAE_wrapper(buffer, data_dim = state_dim, action_dim = action_dim, env_dim = config['NUM_TRAINING_ENVS'], latent_dim = config['LATENT_DIM'], use_e = True)\n","        #vae_wrapper =  VAE_wrapper(buffer, data_dim = state_dim, action_dim = action_dim, env_dim = config['NUM_TRAINING_ENVS'], latent_dim = 8, use_e = True)\n","        \n","        vae_wrapper.train(num_updates=config[\"NUM_STEPS_TRAIN_VAE_MODEL\"])\n","        #vae_wrapper.start_phase2(n_samples = config['PHASE2_SAMPLES'])\n","        vae_wrapper.pa_list = [0,1,2,3,4,5,6,7] #, 8, 9, 10, 11]\n","        \n","\n","        #causal_features_encoder = FeaturesEncoder(\n","        #    input_size=config[\"LATENT_DIM\"], representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"] )\n","\n","        #policy_network = StudentNetwork_2hidden(in_dim=config[\"REP_SIZE\"], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","        policy_network = StudentNetwork(in_dim=config[\"LATENT_DIM\"], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","        \n","\n","\n","        # pylint: disable=redefined-builtin\n","        class CausalFeaturesEncoder(nn.Module):\n","            def __init__(self, input_size, representation_size, width):\n","                super().__init__()\n","\n","                self.layers = nn.Sequential(\n","                    nn.Linear(input_size, 32),\n","                    nn.ELU(),\n","                    nn.Linear(32, 64),\n","                    nn.ELU(),\n","                    nn.Linear(64, 96),\n","                    nn.ELU(),\n","                    nn.Linear(96,  32),\n","                    nn.ELU(),          \n","                    nn.Linear(32, representation_size),\n","                )\n","\n","            def forward(self, x):\n","                return self.layers(x)\n","\n","\n","\n","        phase3_obs_to_latent_encoder = CausalFeaturesEncoder(\n","            input_size=state_dim, representation_size=config[\"LATENT_DIM\"], width=config[\"MLP_WIDTHS\"] )\n","        \n","        #causal_features_encoder = FeaturesEncoder(\n","        #            input_size=state_dim, representation_size = len(vae_wrapper.pa_list), width=config[\"MLP_WIDTHS\"])\n","\n","        #policy_network = StudentNetwork(in_dim = config['LATENT_DIM'], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","\n","        \n","        return iVAE_IRMStudent(\n","            env=env,\n","            vae_wrapper = vae_wrapper,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            phase3_obs_to_latent_encoder = phase3_obs_to_latent_encoder,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","        \n","\n","\n","    ##########################       ICIL        #######################\n","\n","    elif config['METHOD'] == 'ICIL':\n","        energy_model = EnergyModel(\n","            in_dim=state_dim,\n","            width=config[\"MLP_WIDTHS\"],\n","            batch_size=batch_size,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            buffer=buffer,\n","            sgld_buffer_size=config[\"SGLD_BUFFER_SIZE\"],\n","            sgld_learn_rate=config[\"SGLD_LEARN_RATE\"],\n","            sgld_noise_coef=config[\"SGLD_NOISE_COEF\"],\n","            sgld_num_steps=config[\"SGLD_NUM_STEPS\"],\n","            sgld_reinit_freq=config[\"SGLD_REINIT_FREQ\"],\n","        )\n","        energy_model.train(num_updates=config[\"NUM_STEPS_TRAIN_ENERGY_MODEL\"])\n","\n","        causal_features_decoder = FeaturesDecoder(action_size=action_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","\n","        observations_decoder = ObservationsDecoder(representation_size=config[\"REP_SIZE\"], out_size=state_dim, width=config[\"MLP_WIDTHS\"] )\n","\n","        env_discriminator = EnvDiscriminator(representation_size=config[\"REP_SIZE\"], num_envs=config[\"NUM_TRAINING_ENVS\"], width=config[\"MLP_WIDTHS\"])\n","\n","        noise_features_encoders = [FeaturesEncoder(input_size=state_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])  \n","            for i in range(num_training_envs)]\n","        \n","        noise_features_decoders = [FeaturesDecoder(action_size=action_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","            for i in range(num_training_envs)]\n","\n","        mine_network = MineNetwork(x_dim=config[\"REP_SIZE\"], z_dim=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","\n","        return ICILStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            noise_features_encoders=noise_features_encoders,\n","            causal_features_decoder=causal_features_decoder,\n","            noise_features_decoders=noise_features_decoders,\n","            observations_decoder=observations_decoder,\n","            env_discriminator=env_discriminator,\n","            policy_network=policy_network,\n","            energy_model=energy_model,\n","            mine_network=mine_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","def init_arg():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--env_name\", default=\"CartPole-v1\")\n","    parser.add_argument(\"--num_trajectories\", default=20, type=int)\n","    parser.add_argument(\"--trial\", default=0, type=int)\n","    return parser.parse_args()\n"],"metadata":{"id":"BYsHrHrlffKj","executionInfo":{"status":"ok","timestamp":1651001114176,"user_tz":240,"elapsed":361,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- BCINV -- CartPole"],"metadata":{"id":"Lkejd0k3UWIi"}},{"cell_type":"code","source":["config['ENV'] = 'CartPole-v1'\n","config['METHOD'] = \"BCINV\"\n","\n","for traj_num in [1, 2, 5, 10, 20, 30, 40, 50]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","\n","    config['ALG'] = \"FINAL_APR26_BCINVStudent_replicatedata_trajnum\" + str(traj_num)\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BC\"\n","    #config['ENV'] == \"CartPole-v1\"\n","    #config['ENV'] == \"LunarLander-v2\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 20\n","    #config[\"TRAJ_SHIFT\"] = 20\n","    ###############.  settings   ###############\n","\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)"],"metadata":{"id":"iS_lRP8MUWIi","executionInfo":{"status":"error","timestamp":1651001623657,"user_tz":240,"elapsed":506823,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c12e823e-0c7e-49c2-b876-3f096ac079a9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Config: {'ENV': 'CartPole-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum1', 'NUM_TRAJS_GIVEN': 1, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 1, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  CartPole-v1\n","Run 1 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.04137304425239563, entropy -0.27204039692878723, env classifier loss 0.9323762059211731\t\n","\n","epoch 0/100 return: 125.0\n","epoch 10/100 return: 119.0\n","epoch 20/100 return: 128.0\n","epoch 30/100 return: 126.0\n","epoch 40/100 return: 130.0\n","epoch 50/100 return: 126.0\n","epoch 60/100 return: 131.0\n","epoch 70/100 return: 127.0\n","epoch 80/100 return: 126.0\n","epoch 90/100 return: 128.0\n","###############    Reward for test environment for run 1: 126.77.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.03481496870517731, entropy -0.30729466676712036, env classifier loss 0.5280242562294006\t\n","\n","epoch 0/100 return: 19.0\n","epoch 10/100 return: 25.0\n","epoch 20/100 return: 23.0\n","epoch 30/100 return: 23.0\n","epoch 40/100 return: 23.0\n","epoch 50/100 return: 17.0\n","epoch 60/100 return: 23.0\n","epoch 70/100 return: 27.0\n","epoch 80/100 return: 39.0\n","epoch 90/100 return: 29.0\n","###############    Reward for test environment for run 2: 31.36.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.10328465700149536, entropy -0.30600154399871826, env classifier loss 0.7331516146659851\t\n","\n","epoch 0/100 return: 39.0\n","epoch 10/100 return: 32.0\n","epoch 20/100 return: 29.0\n","epoch 30/100 return: 59.0\n","epoch 40/100 return: 27.0\n","epoch 50/100 return: 55.0\n","epoch 60/100 return: 46.0\n","epoch 70/100 return: 39.0\n","epoch 80/100 return: 99.0\n","epoch 90/100 return: 40.0\n","###############    Reward for test environment for run 3: 45.57.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.05752642825245857, entropy -0.2150503695011139, env classifier loss 1.0997389554977417\t\n","\n","epoch 0/100 return: 28.0\n","epoch 10/100 return: 32.0\n","epoch 20/100 return: 50.0\n","epoch 30/100 return: 28.0\n","epoch 40/100 return: 50.0\n","epoch 50/100 return: 27.0\n","epoch 60/100 return: 26.0\n","epoch 70/100 return: 32.0\n","epoch 80/100 return: 47.0\n","epoch 90/100 return: 76.0\n","###############    Reward for test environment for run 4: 45.84.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.2713741064071655, entropy -0.323805570602417, env classifier loss 0.6959092617034912\t\n","\n","epoch 0/100 return: 500.0\n","epoch 10/100 return: 500.0\n","epoch 20/100 return: 500.0\n","epoch 30/100 return: 500.0\n","epoch 40/100 return: 500.0\n","epoch 50/100 return: 500.0\n","epoch 60/100 return: 500.0\n","epoch 70/100 return: 500.0\n","epoch 80/100 return: 500.0\n","epoch 90/100 return: 500.0\n","###############    Reward for test environment for run 5: 500.0.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 8\n","epoch 9000/10000, ce loss 0.2560025453567505, entropy -0.0701652318239212, env classifier loss 1.2563278675079346\t\n","\n","epoch 0/100 return: 39.0\n","epoch 10/100 return: 54.0\n","epoch 20/100 return: 36.0\n","epoch 30/100 return: 47.0\n","epoch 40/100 return: 56.0\n","epoch 50/100 return: 45.0\n","epoch 60/100 return: 67.0\n","epoch 70/100 return: 45.0\n","epoch 80/100 return: 58.0\n","epoch 90/100 return: 34.0\n","###############    Reward for test environment for run 6: 43.62.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 8\n","epoch 4000/10000, ce loss 0.27412500977516174, entropy -0.3065129518508911, env classifier loss 0.5911185145378113\t"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-68b3256e18c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run %s out of %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrun_seed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NUM_REPETITIONS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mstudent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_student\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NUM_STEPS_TRAIN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             env_wrapper_out_of_sample = EnvWrapper(\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/student/bc_inv_student.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_updates)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mupdate_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_discriminator_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m#print(update_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/student/bc_inv_student.py\u001b[0m in \u001b[0;36m_update_networks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mrep_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QtcLdOEv4n9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- BCINV -- LunarLander"],"metadata":{"id":"8Ida7PsnlHlB"}},{"cell_type":"code","source":["config['ENV'] = 'LunarLander-v2'\n","config['METHOD'] = \"BCINV\"\n","\n","for traj_num in [2, 4, 8, 16, 32, 64, 128]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","\n","\n","    config['ALG'] = \"FINAL_APR25_BCINVStudent_replicatedata_trajnum\" + str(traj_num)\n","\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BC\"\n","    #config['ENV'] == \"CartPole-v1\"\n","    #config['ENV'] == \"LunarLander-v2\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 20\n","    #config[\"TRAJ_SHIFT\"] = 20\n","    ###############.  settings   ###############\n","\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1650962629539,"user_tz":240,"elapsed":14133122,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"624cc4fa-cf69-4864-ef9e-5e045344a675","id":"qgSL-rJSlHlK"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum2', 'NUM_TRAJS_GIVEN': 2, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 2, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0008463564445264637, entropy -0.34309858083724976, env classifier loss 0.712557315826416\tepoch 0/100 return: -345.18841303483777\n","epoch 10/100 return: -330.2077946976142\n","epoch 20/100 return: -576.4003228144622\n","epoch 30/100 return: -229.52204096014694\n","epoch 40/100 return: -456.66983005331537\n","epoch 50/100 return: -340.6985752615544\n","epoch 60/100 return: -264.02095155990213\n","epoch 70/100 return: -438.5348578119031\n","epoch 80/100 return: -438.27217059562327\n","epoch 90/100 return: -143.91784825606516\n","###############    Reward for test environment for run 1: -346.83284652790746.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.002049071015790105, entropy -0.3431432843208313, env classifier loss 0.6850289106369019\tepoch 0/100 return: -294.8703179486253\n","epoch 10/100 return: -44.98446727115487\n","epoch 20/100 return: -259.13564443513457\n","epoch 30/100 return: -331.98988519127516\n","epoch 40/100 return: -400.4700457346453\n","epoch 50/100 return: -260.3523074007909\n","epoch 60/100 return: -170.70851421186646\n","epoch 70/100 return: -60.353543988874435\n","epoch 80/100 return: -281.2078858926667\n","epoch 90/100 return: -334.82180275891403\n","###############    Reward for test environment for run 2: -289.38000819649636.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0013958124909549952, entropy -0.3326371908187866, env classifier loss 0.6716716885566711\tepoch 0/100 return: -188.4019748204934\n","epoch 10/100 return: -436.7819792813812\n","epoch 20/100 return: -663.456569044009\n","epoch 30/100 return: -279.2681939757723\n","epoch 40/100 return: 8.493733315969896\n","epoch 50/100 return: -383.77400755149165\n","epoch 60/100 return: -486.5795038080955\n","epoch 70/100 return: -459.7734480842248\n","epoch 80/100 return: -533.5681036741532\n","epoch 90/100 return: -488.7834960639499\n","###############    Reward for test environment for run 3: -362.79476040467927.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0018558698939159513, entropy -0.34028860926628113, env classifier loss 0.6555982232093811\tepoch 0/100 return: -64.98470543092444\n","epoch 10/100 return: -97.07922246646052\n","epoch 20/100 return: -66.23921347830284\n","epoch 30/100 return: -78.4360290399888\n","epoch 40/100 return: -111.99085729827652\n","epoch 50/100 return: -69.38073473779392\n","epoch 60/100 return: -512.748455000321\n","epoch 70/100 return: -208.20362369548295\n","epoch 80/100 return: -120.02212731360709\n","epoch 90/100 return: -67.83113527150692\n","###############    Reward for test environment for run 4: -156.47378768944753.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3150444030761719, entropy -0.3298425078392029, env classifier loss 0.6591383814811707\tepoch 0/100 return: 7.20784627846119\n","epoch 10/100 return: 44.6114018581728\n","epoch 20/100 return: 15.231605117150352\n","epoch 30/100 return: 42.9887995134676\n","epoch 40/100 return: 17.99109079181102\n","epoch 50/100 return: 28.642370757357924\n","epoch 60/100 return: 57.18269990731048\n","epoch 70/100 return: -17.53247548686339\n","epoch 80/100 return: -204.87470801706507\n","epoch 90/100 return: 58.929422721269674\n","###############    Reward for test environment for run 5: -23.135364411528798.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0027507171034812927, entropy -0.34499219059944153, env classifier loss 0.684008777141571\tepoch 0/100 return: -74.65677852511877\n","epoch 10/100 return: 270.19545996568377\n","epoch 20/100 return: -58.578836144332364\n","epoch 30/100 return: 201.0998762006081\n","epoch 40/100 return: 20.59984268350368\n","epoch 50/100 return: -70.71568000239388\n","epoch 60/100 return: -69.6471076824547\n","epoch 70/100 return: -230.11653819396867\n","epoch 80/100 return: 3.1962469591569374\n","epoch 90/100 return: 234.8675276467036\n","###############    Reward for test environment for run 6: -31.478647450159965.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0014509259490296245, entropy -0.34418153762817383, env classifier loss 0.670801043510437\tepoch 0/100 return: -131.66832321409728\n","epoch 10/100 return: -25.35501069937824\n","epoch 20/100 return: -102.95142099175447\n","epoch 30/100 return: -133.7897866721135\n","epoch 40/100 return: -65.09697678306554\n","epoch 50/100 return: -35.1083748837423\n","epoch 60/100 return: 20.61946109755678\n","epoch 70/100 return: 11.299130634391531\n","epoch 80/100 return: -425.20374083439054\n","epoch 90/100 return: 50.79830814772541\n","###############    Reward for test environment for run 7: -68.9911662225362.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.003337904578074813, entropy -0.3353120684623718, env classifier loss 0.6689633727073669\tepoch 0/100 return: -60.75014438832185\n","epoch 10/100 return: -110.31647000151916\n","epoch 20/100 return: -336.0207632103069\n","epoch 30/100 return: -134.42634888222884\n","epoch 40/100 return: -463.8248893669651\n","epoch 50/100 return: -506.79008629218686\n","epoch 60/100 return: -460.28622317827467\n","epoch 70/100 return: -147.28254274680225\n","epoch 80/100 return: -151.4333306070301\n","epoch 90/100 return: -365.3893772910605\n","###############    Reward for test environment for run 8: -282.27816364278317.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0013675478985533118, entropy -0.3361683785915375, env classifier loss 0.6860982179641724\tepoch 0/100 return: -382.94361357336504\n","epoch 10/100 return: -165.58168981414508\n","epoch 20/100 return: -383.8057880992099\n","epoch 30/100 return: -258.1811897560874\n","epoch 40/100 return: -63.07080692814668\n","epoch 50/100 return: -22.547905583210976\n","epoch 60/100 return: -159.56595164123536\n","epoch 70/100 return: -358.1444933598987\n","epoch 80/100 return: -348.7606269197727\n","epoch 90/100 return: 60.48660725169839\n","###############    Reward for test environment for run 9: -67.16244890596187.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0036397443618625402, entropy -0.33221280574798584, env classifier loss 0.6259489059448242\tepoch 0/100 return: -355.4062189033547\n","epoch 10/100 return: 45.80326761658394\n","epoch 20/100 return: -19.903973432416397\n","epoch 30/100 return: -393.3063852425728\n","epoch 40/100 return: 21.53252240542514\n","epoch 50/100 return: 18.923568159747642\n","epoch 60/100 return: -82.08437780354082\n","epoch 70/100 return: 9.370121517471658\n","epoch 80/100 return: -514.9872186584427\n","epoch 90/100 return: 28.292585523094374\n","###############    Reward for test environment for run 10: -185.4899312789364.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0008826159755699337, entropy -0.34189581871032715, env classifier loss 0.6745504140853882\tepoch 0/100 return: -730.7766445560335\n","epoch 10/100 return: -601.9877825295393\n","epoch 20/100 return: -789.7715683861913\n","epoch 30/100 return: -183.16556705497533\n","epoch 40/100 return: -664.5306134292823\n","epoch 50/100 return: -55.09060670368332\n","epoch 60/100 return: -308.28038832441086\n","epoch 70/100 return: -213.368855209466\n","epoch 80/100 return: -557.5092119675087\n","epoch 90/100 return: -265.8743333142288\n","###############    Reward for test environment for run 11: -283.0726311472373.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0013555085752159357, entropy -0.34247589111328125, env classifier loss 0.6586278080940247\tepoch 0/100 return: -202.4868630256733\n","epoch 10/100 return: -232.2132537609277\n","epoch 20/100 return: -322.36102707116004\n","epoch 30/100 return: -409.8544114409411\n","epoch 40/100 return: 197.4852939440751\n","epoch 50/100 return: -7.02507898520615\n","epoch 60/100 return: -217.5533639165707\n","epoch 70/100 return: -37.69457863143212\n","epoch 80/100 return: -339.717193451199\n","epoch 90/100 return: -74.58835239173587\n","###############    Reward for test environment for run 12: -216.58541775119167.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0005693762213923037, entropy -0.34033846855163574, env classifier loss 0.6933358311653137\tepoch 0/100 return: -97.35908008209721\n","epoch 10/100 return: -757.5166385913515\n","epoch 20/100 return: -77.01784472881607\n","epoch 30/100 return: 18.539030808597644\n","epoch 40/100 return: -93.89392773115615\n","epoch 50/100 return: -47.86415752149887\n","epoch 60/100 return: -50.488872649798864\n","epoch 70/100 return: -8.231997531100419\n","epoch 80/100 return: -16.023027590233227\n","epoch 90/100 return: -174.63985090865418\n","###############    Reward for test environment for run 13: -161.36713844716607.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0037767018657177687, entropy -0.3357212543487549, env classifier loss 0.6945827603340149\tepoch 0/100 return: 40.657062293692945\n","epoch 10/100 return: -102.3203148756975\n","epoch 20/100 return: 1.5168774730744907\n","epoch 30/100 return: 19.09824601966919\n","epoch 40/100 return: -131.77473688973473\n","epoch 50/100 return: -114.99781789782799\n","epoch 60/100 return: -14.57860867046044\n","epoch 70/100 return: -101.1357870640156\n","epoch 80/100 return: -140.34539809853547\n","epoch 90/100 return: -135.73070221213163\n","###############    Reward for test environment for run 14: -78.13946013265944.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.012489444576203823, entropy -0.3319728672504425, env classifier loss 0.7239899039268494\tepoch 0/100 return: -9.280805753597818\n","epoch 10/100 return: -179.25343682852542\n","epoch 20/100 return: -292.5349275025178\n","epoch 30/100 return: 1.6736834771543556\n","epoch 40/100 return: 2.2840400979219737\n","epoch 50/100 return: -194.94020863359083\n","epoch 60/100 return: -4.832398641422628\n","epoch 70/100 return: -12.922572565402149\n","epoch 80/100 return: -116.91041374182745\n","epoch 90/100 return: 0.1889570924148245\n","###############    Reward for test environment for run 15: -93.36733631364643.   ###############\n","\n","\n","Average reward for 10 repetitions: -176.43660723482247\n","ALL RESULTS TRAIL: [-176.43660723482247]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum4', 'NUM_TRAJS_GIVEN': 4, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 4, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.08938557654619217, entropy -0.3114025592803955, env classifier loss 0.7326744794845581\tepoch 0/100 return: -550.205624459398\n","epoch 10/100 return: -294.8906124044645\n","epoch 20/100 return: -357.9058101023995\n","epoch 30/100 return: -192.93383214246165\n","epoch 40/100 return: -550.7369355691012\n","epoch 50/100 return: -294.5711840148307\n","epoch 60/100 return: -439.31357320463405\n","epoch 70/100 return: 215.20062224946327\n","epoch 80/100 return: -254.05106575024587\n","epoch 90/100 return: -231.756494751931\n","###############    Reward for test environment for run 1: -303.87986589119487.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.30730772018432617, entropy -0.33345112204551697, env classifier loss 0.6388865113258362\tepoch 0/100 return: -541.9508064631282\n","epoch 10/100 return: -539.8558696125583\n","epoch 20/100 return: -411.3405109801695\n","epoch 30/100 return: -283.81416196713747\n","epoch 40/100 return: 37.17841868817345\n","epoch 50/100 return: -522.8216479787302\n","epoch 60/100 return: -374.6702553209829\n","epoch 70/100 return: -147.57909699527906\n","epoch 80/100 return: -450.94544438494415\n","epoch 90/100 return: -428.18018326384663\n","###############    Reward for test environment for run 2: -311.59933493654034.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.14511558413505554, entropy -0.33148324489593506, env classifier loss 0.7047512531280518\tepoch 0/100 return: -30.36671634323963\n","epoch 10/100 return: 295.2660432138148\n","epoch 20/100 return: -144.74275130016437\n","epoch 30/100 return: 2.925475786385803\n","epoch 40/100 return: -46.48424055879018\n","epoch 50/100 return: 229.06823725216648\n","epoch 60/100 return: -36.81991055443331\n","epoch 70/100 return: -326.1979920731585\n","epoch 80/100 return: 261.1595256444183\n","epoch 90/100 return: 75.77691438130024\n","###############    Reward for test environment for run 3: 106.26736892254264.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0074690403416752815, entropy -0.3401602804660797, env classifier loss 0.7162140607833862\tepoch 0/100 return: 272.9516460175878\n","epoch 10/100 return: 52.28223910288557\n","epoch 20/100 return: 225.68100651023957\n","epoch 30/100 return: 79.86583783432275\n","epoch 40/100 return: -589.0646997126339\n","epoch 50/100 return: -48.38083331809365\n","epoch 60/100 return: 279.72539000267045\n","epoch 70/100 return: 215.6604798238012\n","epoch 80/100 return: 34.30999174085281\n","epoch 90/100 return: 137.5728584874273\n","###############    Reward for test environment for run 4: 67.5399653505062.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.29426124691963196, entropy -0.3397543132305145, env classifier loss 0.6557736992835999\tepoch 0/100 return: -123.56144023727401\n","epoch 10/100 return: -30.88974319764162\n","epoch 20/100 return: -89.94379989140802\n","epoch 30/100 return: 102.5995685484056\n","epoch 40/100 return: -0.7662608824422534\n","epoch 50/100 return: -108.76239516777332\n","epoch 60/100 return: -65.6941270920412\n","epoch 70/100 return: -87.34677457769033\n","epoch 80/100 return: -101.76187193514224\n","epoch 90/100 return: 283.8327324194075\n","###############    Reward for test environment for run 5: -83.94112494820392.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.011053693480789661, entropy -0.34394603967666626, env classifier loss 0.6773557662963867\tepoch 0/100 return: -569.2691536955709\n","epoch 10/100 return: -393.5090743216875\n","epoch 20/100 return: -297.28028084587663\n","epoch 30/100 return: -474.7530220242018\n","epoch 40/100 return: -626.1082013321175\n","epoch 50/100 return: -440.613162446653\n","epoch 60/100 return: -591.4602820776392\n","epoch 70/100 return: -553.029747824823\n","epoch 80/100 return: -521.4996476652682\n","epoch 90/100 return: -553.0273122890374\n","###############    Reward for test environment for run 6: -494.7963737766746.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.06501810252666473, entropy -0.34020593762397766, env classifier loss 0.6959365606307983\tepoch 0/100 return: 38.031532156459605\n","epoch 10/100 return: -35.184243456108646\n","epoch 20/100 return: -61.11667582538311\n","epoch 30/100 return: -7.017619258289045\n","epoch 40/100 return: 23.55386455457989\n","epoch 50/100 return: -121.5795027158179\n","epoch 60/100 return: -102.81806158207583\n","epoch 70/100 return: -36.826734050075714\n","epoch 80/100 return: 72.04799015714383\n","epoch 90/100 return: 35.14185691850554\n","###############    Reward for test environment for run 7: 9.82940087582448.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.005556754767894745, entropy -0.33715689182281494, env classifier loss 0.7180558443069458\tepoch 0/100 return: 11.061785710550836\n","epoch 10/100 return: 3.740597926662602\n","epoch 20/100 return: 24.781027213273845\n","epoch 30/100 return: -55.42553790732073\n","epoch 40/100 return: 3.0431122215493076\n","epoch 50/100 return: 57.294053615586904\n","epoch 60/100 return: 51.59165725414039\n","epoch 70/100 return: -61.78346483864627\n","epoch 80/100 return: -85.23044516310384\n","epoch 90/100 return: -97.3288138022119\n","###############    Reward for test environment for run 8: -12.079876453289575.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.06507183611392975, entropy -0.3423224091529846, env classifier loss 0.7065935730934143\tepoch 0/100 return: -522.5775605077081\n","epoch 10/100 return: 41.964491608851716\n","epoch 20/100 return: 295.81883445932317\n","epoch 30/100 return: -422.25338277347686\n","epoch 40/100 return: 274.480049964983\n","epoch 50/100 return: 212.68375391511705\n","epoch 60/100 return: -77.7623057130571\n","epoch 70/100 return: -39.40039661757962\n","epoch 80/100 return: -20.72204050162972\n","epoch 90/100 return: -20.75883272405524\n","###############    Reward for test environment for run 9: -66.68288280706736.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.007723044604063034, entropy -0.34187421202659607, env classifier loss 0.7012482285499573\tepoch 0/100 return: -569.3487486714836\n","epoch 10/100 return: -446.88414774697577\n","epoch 20/100 return: -541.1778626297732\n","epoch 30/100 return: -306.9817796783325\n","epoch 40/100 return: -532.7152423150434\n","epoch 50/100 return: 230.27767814859968\n","epoch 60/100 return: 205.11916485219456\n","epoch 70/100 return: 9.166298006142227\n","epoch 80/100 return: 46.546604069496105\n","epoch 90/100 return: -519.2820893820835\n","###############    Reward for test environment for run 10: -187.48376685842297.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.12959212064743042, entropy -0.3355298638343811, env classifier loss 0.7230929136276245\tepoch 0/100 return: -478.1417078880418\n","epoch 10/100 return: -132.17984151583403\n","epoch 20/100 return: -483.5533584872107\n","epoch 30/100 return: -470.9575319671219\n","epoch 40/100 return: -507.2448700866081\n","epoch 50/100 return: -459.88865179432474\n","epoch 60/100 return: -326.11860925830314\n","epoch 70/100 return: -459.1883818575194\n","epoch 80/100 return: -452.3195643657164\n","epoch 90/100 return: -423.9151490273156\n","###############    Reward for test environment for run 11: -350.27974647194895.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.013155209831893444, entropy -0.3342263400554657, env classifier loss 0.6443620920181274\tepoch 0/100 return: 4.221341051004289\n","epoch 10/100 return: 8.807691428690008\n","epoch 20/100 return: 145.3602892440793\n","epoch 30/100 return: -44.48769105654901\n","epoch 40/100 return: -159.140108399895\n","epoch 50/100 return: 218.48949719319256\n","epoch 60/100 return: -25.950377584013523\n","epoch 70/100 return: 253.43090011430513\n","epoch 80/100 return: 202.12074542333227\n","epoch 90/100 return: 25.723696628779148\n","###############    Reward for test environment for run 12: 38.46710393606579.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.06368885189294815, entropy -0.33377742767333984, env classifier loss 0.6977798342704773\tepoch 0/100 return: 116.59289759164861\n","epoch 10/100 return: 155.57185204779597\n","epoch 20/100 return: -261.1488270226773\n","epoch 30/100 return: 42.94633323263596\n","epoch 40/100 return: 168.553108785612\n","epoch 50/100 return: -189.13706024223274\n","epoch 60/100 return: 222.89605846664432\n","epoch 70/100 return: -139.1003853912863\n","epoch 80/100 return: 14.90061314097214\n","epoch 90/100 return: -144.91827449299876\n","###############    Reward for test environment for run 13: 77.53996388226815.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.02494073286652565, entropy -0.3234415054321289, env classifier loss 0.6622840166091919\tepoch 0/100 return: -223.96721846327952\n","epoch 10/100 return: 260.90829058491437\n","epoch 20/100 return: -305.55309030380124\n","epoch 30/100 return: -432.5990759509154\n","epoch 40/100 return: -416.50445050065105\n","epoch 50/100 return: 242.07243638145601\n","epoch 60/100 return: -28.175588477183283\n","epoch 70/100 return: -238.2183643333945\n","epoch 80/100 return: 244.14672885228288\n","epoch 90/100 return: 254.11038349001663\n","###############    Reward for test environment for run 14: -56.10307181362908.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.0047475420869886875, entropy -0.3402705192565918, env classifier loss 0.6316235661506653\tepoch 0/100 return: 53.41029051821578\n","epoch 10/100 return: 100.84898401256845\n","epoch 20/100 return: 204.19599387129034\n","epoch 30/100 return: 237.6572926284251\n","epoch 40/100 return: 238.02451867860023\n","epoch 50/100 return: 95.23259187763927\n","epoch 60/100 return: 94.10866972948438\n","epoch 70/100 return: 262.98975623991\n","epoch 80/100 return: 197.64635403885234\n","epoch 90/100 return: 106.37119969411931\n","###############    Reward for test environment for run 15: 171.9638400394848.   ###############\n","\n","\n","Average reward for 10 repetitions: -93.0158933966853\n","ALL RESULTS TRAIL: [-93.0158933966853]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum8', 'NUM_TRAJS_GIVEN': 8, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 8, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.11434561014175415, entropy -0.34010738134384155, env classifier loss 0.6709505915641785\tepoch 0/100 return: -239.35650198416036\n","epoch 10/100 return: 278.368625834231\n","epoch 20/100 return: -74.67431809833235\n","epoch 30/100 return: 275.10926082382207\n","epoch 40/100 return: -301.34858603985896\n","epoch 50/100 return: -11.362562195088216\n","epoch 60/100 return: -72.18509169645752\n","epoch 70/100 return: 262.9513072282388\n","epoch 80/100 return: 194.27567055739394\n","epoch 90/100 return: -66.72043987702111\n","###############    Reward for test environment for run 1: 114.1411899415655.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.311325341463089, entropy -0.29872632026672363, env classifier loss 0.750063955783844\tepoch 0/100 return: -46.56908005119285\n","epoch 10/100 return: -57.94087445798118\n","epoch 20/100 return: 229.2430439630047\n","epoch 30/100 return: 250.11521285908088\n","epoch 40/100 return: 257.0917651976331\n","epoch 50/100 return: 261.6144274931105\n","epoch 60/100 return: 196.10853111000955\n","epoch 70/100 return: 43.740617129978034\n","epoch 80/100 return: -59.84600534698008\n","epoch 90/100 return: 237.0266746482692\n","###############    Reward for test environment for run 2: 106.90014995867527.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.01246410608291626, entropy -0.3383582532405853, env classifier loss 0.701708972454071\tepoch 0/100 return: 55.80535338420408\n","epoch 10/100 return: 34.955014225316944\n","epoch 20/100 return: 97.15672342936803\n","epoch 30/100 return: 93.8166029208913\n","epoch 40/100 return: 38.151936078505344\n","epoch 50/100 return: 38.0348667122926\n","epoch 60/100 return: 36.5111523627731\n","epoch 70/100 return: 13.905484395476783\n","epoch 80/100 return: 50.91848151423714\n","epoch 90/100 return: 51.37505684354454\n","###############    Reward for test environment for run 3: 73.31870064570992.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.1299709975719452, entropy -0.34242305159568787, env classifier loss 0.7133329510688782\tepoch 0/100 return: -271.29304430066327\n","epoch 10/100 return: -232.87761484902651\n","epoch 20/100 return: 24.784744826842655\n","epoch 30/100 return: -51.048734783020194\n","epoch 40/100 return: -327.86538046963096\n","epoch 50/100 return: 242.6867534462222\n","epoch 60/100 return: 2.7664653756574324\n","epoch 70/100 return: -282.1438052325044\n","epoch 80/100 return: -303.96203655584384\n","epoch 90/100 return: -297.25475764162593\n","###############    Reward for test environment for run 4: -115.8304420577849.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.12655623257160187, entropy -0.33969610929489136, env classifier loss 0.678392767906189\tepoch 0/100 return: 108.69028743043046\n","epoch 10/100 return: 262.7738161215158\n","epoch 20/100 return: 160.7511879505614\n","epoch 30/100 return: 257.525163348809\n","epoch 40/100 return: 281.34265543865627\n","epoch 50/100 return: 256.6573179855477\n","epoch 60/100 return: 248.0035172844781\n","epoch 70/100 return: 244.7957123943551\n","epoch 80/100 return: 273.46664331470083\n","epoch 90/100 return: 281.3469761090593\n","###############    Reward for test environment for run 5: 182.5769984472436.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.13016274571418762, entropy -0.3369549512863159, env classifier loss 0.6988865733146667\tepoch 0/100 return: -17.039091752646563\n","epoch 10/100 return: -20.764516891154358\n","epoch 20/100 return: 187.82022152938495\n","epoch 30/100 return: 244.81363118693224\n","epoch 40/100 return: 211.7447437369647\n","epoch 50/100 return: 235.54526040934363\n","epoch 60/100 return: -6.162233901996579\n","epoch 70/100 return: -4.724949266014178\n","epoch 80/100 return: 239.62114741516694\n","epoch 90/100 return: 274.91818060163496\n","###############    Reward for test environment for run 6: 181.48010554209705.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.2564968466758728, entropy -0.3392297625541687, env classifier loss 0.6745073795318604\tepoch 0/100 return: -29.238767837942216\n","epoch 10/100 return: 222.93487723319896\n","epoch 20/100 return: -119.86945381244087\n","epoch 30/100 return: -6.800471299132432\n","epoch 40/100 return: -4.955336446912985\n","epoch 50/100 return: 73.20207366248681\n","epoch 60/100 return: -6.8816634861011154\n","epoch 70/100 return: 2.924193219096045\n","epoch 80/100 return: 18.121172503520572\n","epoch 90/100 return: 249.61107245393708\n","###############    Reward for test environment for run 7: 100.41524288254892.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.2051461786031723, entropy -0.33603835105895996, env classifier loss 0.6987340450286865\tepoch 0/100 return: 235.3010135261569\n","epoch 10/100 return: 260.26450572142323\n","epoch 20/100 return: 270.2235883054816\n","epoch 30/100 return: 237.05340875548146\n","epoch 40/100 return: 281.9899660724748\n","epoch 50/100 return: 277.54234598683956\n","epoch 60/100 return: 248.39002193039443\n","epoch 70/100 return: 283.27275776588306\n","epoch 80/100 return: 258.12866599499495\n","epoch 90/100 return: 261.62106776774567\n","###############    Reward for test environment for run 8: 212.01840274189087.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.14122535288333893, entropy -0.34074655175209045, env classifier loss 0.6980192065238953\tepoch 0/100 return: 29.712440228610404\n","epoch 10/100 return: 211.66021257294082\n","epoch 20/100 return: -357.8435928286479\n","epoch 30/100 return: -174.05272738298214\n","epoch 40/100 return: -374.02422286221486\n","epoch 50/100 return: 208.83361858890493\n","epoch 60/100 return: -355.1292295590146\n","epoch 70/100 return: 261.1974590063996\n","epoch 80/100 return: -197.94139038200564\n","epoch 90/100 return: 287.2921088755241\n","###############    Reward for test environment for run 9: -28.740172534672755.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.08672173321247101, entropy -0.3395705223083496, env classifier loss 0.6610462665557861\tepoch 0/100 return: -160.6309731258567\n","epoch 10/100 return: 236.76939944921023\n","epoch 20/100 return: -332.6224260100486\n","epoch 30/100 return: -27.732982520046775\n","epoch 40/100 return: 278.77798755499634\n","epoch 50/100 return: 282.52001605176787\n","epoch 60/100 return: 265.4473931077456\n","epoch 70/100 return: 191.73998587885626\n","epoch 80/100 return: 280.28775667012104\n","epoch 90/100 return: -494.0545910718661\n","###############    Reward for test environment for run 10: 55.813284224488896.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.03382519260048866, entropy -0.34079813957214355, env classifier loss 0.6938740015029907\tepoch 0/100 return: 240.4060975223115\n","epoch 10/100 return: 236.01468379561254\n","epoch 20/100 return: 276.8281677541551\n","epoch 30/100 return: 142.47965385362596\n","epoch 40/100 return: 139.18486992838942\n","epoch 50/100 return: 227.50691358290277\n","epoch 60/100 return: 244.69896292156128\n","epoch 70/100 return: -521.0998290253942\n","epoch 80/100 return: 224.18361185494456\n","epoch 90/100 return: 224.98936574617937\n","###############    Reward for test environment for run 11: 55.445710602789575.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.050045982003211975, entropy -0.33566099405288696, env classifier loss 0.7169140577316284\tepoch 0/100 return: 277.3610700226021\n","epoch 10/100 return: 258.5214538783637\n","epoch 20/100 return: 225.80612900019912\n","epoch 30/100 return: 258.7998398271412\n","epoch 40/100 return: 265.2115404541279\n","epoch 50/100 return: 285.63408766049554\n","epoch 60/100 return: 22.884009523722256\n","epoch 70/100 return: 219.38956659204837\n","epoch 80/100 return: 274.72454763729036\n","epoch 90/100 return: 276.9667902528339\n","###############    Reward for test environment for run 12: 75.18956604280939.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3014974892139435, entropy -0.3412139415740967, env classifier loss 0.6776890158653259\tepoch 0/100 return: -404.2603882142688\n","epoch 10/100 return: -28.282985671067934\n","epoch 20/100 return: -385.7130276984383\n","epoch 30/100 return: -419.0208054150516\n","epoch 40/100 return: -102.77823437016902\n","epoch 50/100 return: 265.1185471109067\n","epoch 60/100 return: -261.2414842355471\n","epoch 70/100 return: -200.49676066919147\n","epoch 80/100 return: -382.9500910196081\n","epoch 90/100 return: -227.42236905187838\n","###############    Reward for test environment for run 13: -201.21928528504725.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.1390356868505478, entropy -0.33689719438552856, env classifier loss 0.6747399568557739\tepoch 0/100 return: 227.14226635499946\n","epoch 10/100 return: 247.91536111074157\n","epoch 20/100 return: 226.6799994223123\n","epoch 30/100 return: -610.3757550735595\n","epoch 40/100 return: 253.83932476811123\n","epoch 50/100 return: 265.98624599070706\n","epoch 60/100 return: 253.80482202808534\n","epoch 70/100 return: 257.3513029700926\n","epoch 80/100 return: 245.44672964779346\n","epoch 90/100 return: 26.02494028969602\n","###############    Reward for test environment for run 14: 134.91247257771445.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.04741601645946503, entropy -0.34424343705177307, env classifier loss 0.6751928925514221\tepoch 0/100 return: -526.3545296863773\n","epoch 10/100 return: -378.799299900149\n","epoch 20/100 return: 78.56278932843558\n","epoch 30/100 return: -458.06680314574766\n","epoch 40/100 return: -475.31014356794157\n","epoch 50/100 return: -502.25900236072533\n","epoch 60/100 return: -568.7788494191038\n","epoch 70/100 return: -535.7425115516758\n","epoch 80/100 return: -436.5687656647349\n","epoch 90/100 return: -317.1193564047938\n","###############    Reward for test environment for run 15: -400.75209252821566.   ###############\n","\n","\n","Average reward for 10 repetitions: 36.37798874678752\n","ALL RESULTS TRAIL: [36.37798874678752]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum16', 'NUM_TRAJS_GIVEN': 16, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 16, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.19532331824302673, entropy -0.33683228492736816, env classifier loss 0.6941048502922058\tepoch 0/100 return: 266.98536953798373\n","epoch 10/100 return: 248.06878850523157\n","epoch 20/100 return: 10.807348313520976\n","epoch 30/100 return: 292.9770941419209\n","epoch 40/100 return: 236.2306835437164\n","epoch 50/100 return: 291.0693221411221\n","epoch 60/100 return: 275.0939081660069\n","epoch 70/100 return: 258.8342323515289\n","epoch 80/100 return: 17.6569550849363\n","epoch 90/100 return: 227.60382163832162\n","###############    Reward for test environment for run 1: 217.75256712149113.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.38071566820144653, entropy -0.34298330545425415, env classifier loss 0.6994959115982056\tepoch 0/100 return: 236.64581881998595\n","epoch 10/100 return: 236.45830072424107\n","epoch 20/100 return: 222.56074732776452\n","epoch 30/100 return: 199.6273468577142\n","epoch 40/100 return: 130.28518244841672\n","epoch 50/100 return: 191.83927075107908\n","epoch 60/100 return: 232.5874150296803\n","epoch 70/100 return: 226.12521028084794\n","epoch 80/100 return: -2.4343630901069604\n","epoch 90/100 return: 35.05545520751652\n","###############    Reward for test environment for run 2: 110.55475488765636.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.34358277916908264, entropy -0.33862364292144775, env classifier loss 0.6763041019439697\tepoch 0/100 return: -450.87326237832326\n","epoch 10/100 return: 73.66542845149061\n","epoch 20/100 return: -14.445542943559417\n","epoch 30/100 return: 266.73882278524445\n","epoch 40/100 return: 284.32923789514666\n","epoch 50/100 return: 50.03225307076359\n","epoch 60/100 return: 56.23816354421466\n","epoch 70/100 return: 6.373366161107029\n","epoch 80/100 return: -6.83563561292171\n","epoch 90/100 return: 41.2960757649051\n","###############    Reward for test environment for run 3: 27.74422182054156.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.20161210000514984, entropy -0.331251323223114, env classifier loss 0.6414987444877625\tepoch 0/100 return: -272.43083322709776\n","epoch 10/100 return: -9.177448202935295\n","epoch 20/100 return: -24.685109274155643\n","epoch 30/100 return: -7.381084804089864\n","epoch 40/100 return: -3.826333124907211\n","epoch 50/100 return: 24.5643920860705\n","epoch 60/100 return: 35.04060717159128\n","epoch 70/100 return: -39.95939924198127\n","epoch 80/100 return: -203.62708319913793\n","epoch 90/100 return: 20.597891222493196\n","###############    Reward for test environment for run 4: -31.32135855235562.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.32347097992897034, entropy -0.33413082361221313, env classifier loss 0.7187352776527405\tepoch 0/100 return: 287.1643607167701\n","epoch 10/100 return: 258.7716374801982\n","epoch 20/100 return: 237.66623866894008\n","epoch 30/100 return: 225.3013804005367\n","epoch 40/100 return: -49.856080392827224\n","epoch 50/100 return: 9.756466109934347\n","epoch 60/100 return: 12.34485137677534\n","epoch 70/100 return: 7.175535691295265\n","epoch 80/100 return: -47.23340194778671\n","epoch 90/100 return: 244.44980891091234\n","###############    Reward for test environment for run 5: 116.70034131922928.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.2824494242668152, entropy -0.327694833278656, env classifier loss 0.7590962648391724\tepoch 0/100 return: 254.5706206937054\n","epoch 10/100 return: 189.07255045319624\n","epoch 20/100 return: 225.24642688996323\n","epoch 30/100 return: 25.386643423841818\n","epoch 40/100 return: 209.37057593696483\n","epoch 50/100 return: 25.410050795713357\n","epoch 60/100 return: 221.06840944239306\n","epoch 70/100 return: 100.06591286224041\n","epoch 80/100 return: 236.38062997488976\n","epoch 90/100 return: -218.81770911776022\n","###############    Reward for test environment for run 6: 136.94587584441425.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.25239622592926025, entropy -0.3381897211074829, env classifier loss 0.6444033980369568\tepoch 0/100 return: -57.40913540349389\n","epoch 10/100 return: 137.9165759138657\n","epoch 20/100 return: -12.605613954856764\n","epoch 30/100 return: 39.34461005245384\n","epoch 40/100 return: 249.5720394987014\n","epoch 50/100 return: 254.234791457245\n","epoch 60/100 return: 245.58207127765053\n","epoch 70/100 return: 140.72121252820205\n","epoch 80/100 return: 262.2338870068466\n","epoch 90/100 return: -95.94681309341937\n","###############    Reward for test environment for run 7: 163.01931490626626.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.22069978713989258, entropy -0.3421868085861206, env classifier loss 0.6872169971466064\tepoch 0/100 return: 273.86029821759905\n","epoch 10/100 return: 264.96818132000817\n","epoch 20/100 return: -81.67706205948551\n","epoch 30/100 return: 257.8875683894019\n","epoch 40/100 return: 251.87407757738387\n","epoch 50/100 return: 259.33472222181626\n","epoch 60/100 return: 272.3090536971223\n","epoch 70/100 return: 259.1445245845839\n","epoch 80/100 return: 258.6946716982279\n","epoch 90/100 return: 268.24167512262346\n","###############    Reward for test environment for run 8: 191.86047379009597.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.2645907402038574, entropy -0.3334769010543823, env classifier loss 0.6743777394294739\tepoch 0/100 return: 288.21106327980135\n","epoch 10/100 return: -169.6376815557205\n","epoch 20/100 return: 276.07300949495163\n","epoch 30/100 return: -358.228340812536\n","epoch 40/100 return: 263.87889775349527\n","epoch 50/100 return: -58.739165658982955\n","epoch 60/100 return: -373.729776920935\n","epoch 70/100 return: 230.02506508143995\n","epoch 80/100 return: 253.08282925135913\n","epoch 90/100 return: -457.57205533786146\n","###############    Reward for test environment for run 9: 95.72469707985837.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.36441245675086975, entropy -0.333720326423645, env classifier loss 0.6835855841636658\tepoch 0/100 return: 20.106846035370065\n","epoch 10/100 return: -408.29592939598905\n","epoch 20/100 return: 173.88276661933764\n","epoch 30/100 return: 197.95912892142388\n","epoch 40/100 return: 271.8734651556116\n","epoch 50/100 return: -427.54221381359616\n","epoch 60/100 return: 45.99819430069406\n","epoch 70/100 return: -185.47308858924578\n","epoch 80/100 return: -182.30191980549418\n","epoch 90/100 return: 90.23938219507664\n","###############    Reward for test environment for run 10: 11.906663940413026.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3239826560020447, entropy -0.332506388425827, env classifier loss 0.6278222799301147\tepoch 0/100 return: -45.80215901805616\n","epoch 10/100 return: 232.24706098069487\n","epoch 20/100 return: -214.438384386676\n","epoch 30/100 return: -190.02381635982033\n","epoch 40/100 return: -91.47416332520064\n","epoch 50/100 return: -192.4538488387437\n","epoch 60/100 return: -69.99308002490284\n","epoch 70/100 return: -198.52641480566035\n","epoch 80/100 return: -123.025012695023\n","epoch 90/100 return: -321.64878086122974\n","###############    Reward for test environment for run 11: -78.04288402108989.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4294228255748749, entropy -0.34075337648391724, env classifier loss 0.7020335793495178\tepoch 0/100 return: 282.4616656979972\n","epoch 10/100 return: 253.7463272487606\n","epoch 20/100 return: 267.7617457651184\n","epoch 30/100 return: 33.34342590551057\n","epoch 40/100 return: 259.3027653208781\n","epoch 50/100 return: 270.827084633069\n","epoch 60/100 return: 278.17724738774257\n","epoch 70/100 return: 237.3290235942362\n","epoch 80/100 return: 131.60694270683845\n","epoch 90/100 return: 249.17944165507933\n","###############    Reward for test environment for run 12: 181.16077706044044.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.29585352540016174, entropy -0.336306631565094, env classifier loss 0.665160059928894\tepoch 0/100 return: 236.51725367974217\n","epoch 10/100 return: 127.40198203453487\n","epoch 20/100 return: 16.4917889245122\n","epoch 30/100 return: 229.28340950063676\n","epoch 40/100 return: -0.2319546729069546\n","epoch 50/100 return: 220.59862251941345\n","epoch 60/100 return: 84.8574406213979\n","epoch 70/100 return: 116.09954373779043\n","epoch 80/100 return: 251.24155406306735\n","epoch 90/100 return: 75.76303763766977\n","###############    Reward for test environment for run 13: 126.71200184804617.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.17433175444602966, entropy -0.34140992164611816, env classifier loss 0.6740866899490356\tepoch 0/100 return: 206.72496479788919\n","epoch 10/100 return: 242.8289411241377\n","epoch 20/100 return: -54.174416064222385\n","epoch 30/100 return: -51.40970660481771\n","epoch 40/100 return: 270.80093915439784\n","epoch 50/100 return: 261.27443481888463\n","epoch 60/100 return: 225.44451698589336\n","epoch 70/100 return: 227.7081787837729\n","epoch 80/100 return: 234.20349365154436\n","epoch 90/100 return: 185.96259042600354\n","###############    Reward for test environment for run 14: 175.79156652871566.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.44713807106018066, entropy -0.3407725989818573, env classifier loss 0.709030270576477\tepoch 0/100 return: 14.937993622915599\n","epoch 10/100 return: 267.1349393513557\n","epoch 20/100 return: 9.203899347373635\n","epoch 30/100 return: 266.4828202006413\n","epoch 40/100 return: 232.59178999556178\n","epoch 50/100 return: 263.1930356102006\n","epoch 60/100 return: -159.75080947198174\n","epoch 70/100 return: 283.5491180318235\n","epoch 80/100 return: 253.66440169807993\n","epoch 90/100 return: 257.0529257995462\n","###############    Reward for test environment for run 15: 218.88302792932808.   ###############\n","\n","\n","Average reward for 10 repetitions: 111.0261361002034\n","ALL RESULTS TRAIL: [111.0261361002034]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum32', 'NUM_TRAJS_GIVEN': 32, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 32, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.574219822883606, entropy -0.3376762270927429, env classifier loss 0.661087691783905\tepoch 0/100 return: 253.72499548449193\n","epoch 10/100 return: 141.74772720713943\n","epoch 20/100 return: 278.5005388905439\n","epoch 30/100 return: 258.96715482767\n","epoch 40/100 return: 261.9879902292188\n","epoch 50/100 return: 256.0481067254923\n","epoch 60/100 return: 244.94488653759933\n","epoch 70/100 return: 240.50862680842576\n","epoch 80/100 return: 294.68251002875843\n","epoch 90/100 return: 255.70680413353801\n","###############    Reward for test environment for run 1: 241.91501445098208.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.47175341844558716, entropy -0.3377455770969391, env classifier loss 0.6774429678916931\tepoch 0/100 return: 258.18895314440397\n","epoch 10/100 return: 272.0257586698267\n","epoch 20/100 return: 255.19033752714685\n","epoch 30/100 return: 261.8764133704917\n","epoch 40/100 return: 245.74591631219175\n","epoch 50/100 return: 269.08059405465383\n","epoch 60/100 return: 268.11213906775413\n","epoch 70/100 return: 262.24431675874973\n","epoch 80/100 return: 236.96459580719235\n","epoch 90/100 return: 174.2365479203798\n","###############    Reward for test environment for run 2: 222.96708185503098.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.32735806703567505, entropy -0.3409145474433899, env classifier loss 0.6759546995162964\tepoch 0/100 return: 262.79442060889517\n","epoch 10/100 return: 127.05198791701677\n","epoch 20/100 return: 295.48554152815035\n","epoch 30/100 return: 248.99278072597966\n","epoch 40/100 return: 224.02226159028817\n","epoch 50/100 return: -2.7905888944125508\n","epoch 60/100 return: 261.808077190717\n","epoch 70/100 return: 273.8915606628676\n","epoch 80/100 return: 270.31785002179913\n","epoch 90/100 return: 236.0488898759053\n","###############    Reward for test environment for run 3: 145.3210006730271.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5297949314117432, entropy -0.34300297498703003, env classifier loss 0.6958885192871094\tepoch 0/100 return: 272.47479801063275\n","epoch 10/100 return: 149.27223273103579\n","epoch 20/100 return: 77.30113822624861\n","epoch 30/100 return: -367.47402028588533\n","epoch 40/100 return: 252.6431616128716\n","epoch 50/100 return: 172.36735085025396\n","epoch 60/100 return: 229.12184883633515\n","epoch 70/100 return: 251.46777786106304\n","epoch 80/100 return: 214.3540553604836\n","epoch 90/100 return: 210.51903662815977\n","###############    Reward for test environment for run 4: 159.47197868813865.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3041427433490753, entropy -0.3150128722190857, env classifier loss 0.6949558258056641\tepoch 0/100 return: 223.13980282408636\n","epoch 10/100 return: -200.66633708030565\n","epoch 20/100 return: -184.02311506523333\n","epoch 30/100 return: 120.81917154958337\n","epoch 40/100 return: 121.63878169515611\n","epoch 50/100 return: 236.70217291710787\n","epoch 60/100 return: 246.05083723954777\n","epoch 70/100 return: 212.8538131447882\n","epoch 80/100 return: 204.38534189284593\n","epoch 90/100 return: 78.73408804796834\n","###############    Reward for test environment for run 5: 204.5083685968479.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.46303004026412964, entropy -0.3430028557777405, env classifier loss 0.6579941511154175\tepoch 0/100 return: 281.4719914891848\n","epoch 10/100 return: 273.69806820757594\n","epoch 20/100 return: 261.5564921041004\n","epoch 30/100 return: 279.0245314889637\n","epoch 40/100 return: 268.13335125028607\n","epoch 50/100 return: 265.90775807292493\n","epoch 60/100 return: 273.7895832633788\n","epoch 70/100 return: 251.7883576055093\n","epoch 80/100 return: 257.88672323553124\n","epoch 90/100 return: -3.6236380038103135\n","###############    Reward for test environment for run 6: 213.28469889335963.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.34361445903778076, entropy -0.3287879228591919, env classifier loss 0.6904762387275696\tepoch 0/100 return: 280.50746600096\n","epoch 10/100 return: 286.15257478882876\n","epoch 20/100 return: -19.14095236387865\n","epoch 30/100 return: 266.0361005719344\n","epoch 40/100 return: 278.9638481175327\n","epoch 50/100 return: 283.0067845908924\n","epoch 60/100 return: -1.8282943231036948\n","epoch 70/100 return: 260.78130583023824\n","epoch 80/100 return: 227.34697835365714\n","epoch 90/100 return: 55.49734873689227\n","###############    Reward for test environment for run 7: 127.81328215230786.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.518259584903717, entropy -0.34035366773605347, env classifier loss 0.6789186000823975\tepoch 0/100 return: 263.34356936958136\n","epoch 10/100 return: 268.33102140309813\n","epoch 20/100 return: 234.12214635769348\n","epoch 30/100 return: 250.70478744107885\n","epoch 40/100 return: 272.75263903661477\n","epoch 50/100 return: 255.0761201673559\n","epoch 60/100 return: 275.776030118751\n","epoch 70/100 return: 228.55942875004183\n","epoch 80/100 return: 254.1573248810905\n","epoch 90/100 return: 112.4530386587779\n","###############    Reward for test environment for run 8: 220.46050173712146.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4074574410915375, entropy -0.33330148458480835, env classifier loss 0.6386769413948059\tepoch 0/100 return: -630.4097887245255\n","epoch 10/100 return: 244.6779258432543\n","epoch 20/100 return: -409.631878847597\n","epoch 30/100 return: 215.67031153041899\n","epoch 40/100 return: 219.89032771330704\n","epoch 50/100 return: -576.8487098542969\n","epoch 60/100 return: 246.77088453989467\n","epoch 70/100 return: -232.78895643947473\n","epoch 80/100 return: 258.2853732731859\n","epoch 90/100 return: 295.4749334421182\n","###############    Reward for test environment for run 9: 139.12045608005366.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.358733594417572, entropy -0.3321203589439392, env classifier loss 0.6551464796066284\tepoch 0/100 return: 57.12011793047807\n","epoch 10/100 return: 199.1655491084074\n","epoch 20/100 return: 17.10054603603967\n","epoch 30/100 return: 234.65641087846495\n","epoch 40/100 return: 31.294735339249158\n","epoch 50/100 return: 17.90945925777153\n","epoch 60/100 return: 159.78118156084048\n","epoch 70/100 return: -351.0595270544178\n","epoch 80/100 return: 262.971546623884\n","epoch 90/100 return: 251.77971809580472\n","###############    Reward for test environment for run 10: 6.671575338464288.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5228938460350037, entropy -0.33687645196914673, env classifier loss 0.7349692583084106\tepoch 0/100 return: 272.3427582619528\n","epoch 10/100 return: 210.2571244120524\n","epoch 20/100 return: 210.94567426901824\n","epoch 30/100 return: -32.765063319121914\n","epoch 40/100 return: 252.23791776751986\n","epoch 50/100 return: -159.14561018134427\n","epoch 60/100 return: 120.51486679540875\n","epoch 70/100 return: 9.483672995231135\n","epoch 80/100 return: -65.01654269212735\n","epoch 90/100 return: 235.5594870180155\n","###############    Reward for test environment for run 11: 112.09923210328132.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4299902021884918, entropy -0.32871612906455994, env classifier loss 0.746280312538147\tepoch 0/100 return: 226.18972977288422\n","epoch 10/100 return: 165.44912134924732\n","epoch 20/100 return: 261.11106637389344\n","epoch 30/100 return: -41.904736272946266\n","epoch 40/100 return: 235.20289771557532\n","epoch 50/100 return: 250.7934298030533\n","epoch 60/100 return: 176.26446237537778\n","epoch 70/100 return: 286.98666941500477\n","epoch 80/100 return: 270.7643107021711\n","epoch 90/100 return: 245.23875725034756\n","###############    Reward for test environment for run 12: 184.1980839945505.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5487468838691711, entropy -0.34096580743789673, env classifier loss 0.698027491569519\tepoch 0/100 return: 8.32754330821284\n","epoch 10/100 return: 18.75549623511516\n","epoch 20/100 return: 154.08123635360548\n","epoch 30/100 return: 59.177269406043706\n","epoch 40/100 return: 180.7080484603341\n","epoch 50/100 return: 68.68679755793644\n","epoch 60/100 return: 36.834542487344514\n","epoch 70/100 return: -0.3138051643714572\n","epoch 80/100 return: 17.439433365004952\n","epoch 90/100 return: 24.759215276862506\n","###############    Reward for test environment for run 13: 78.93473825886578.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3952981233596802, entropy -0.340728759765625, env classifier loss 0.663565456867218\tepoch 0/100 return: 310.15027845640634\n","epoch 10/100 return: 72.81902565243115\n","epoch 20/100 return: 220.39700033746846\n","epoch 30/100 return: 7.168072061526274\n","epoch 40/100 return: 261.110246431249\n","epoch 50/100 return: 60.84231528774504\n","epoch 60/100 return: -16.090295030054904\n","epoch 70/100 return: -12.642005148673718\n","epoch 80/100 return: 36.29421209545987\n","epoch 90/100 return: 231.6140406214217\n","###############    Reward for test environment for run 14: 163.02982591962865.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5614169239997864, entropy -0.337654709815979, env classifier loss 0.663899302482605\tepoch 0/100 return: 272.98774997271676\n","epoch 10/100 return: 35.7035507585492\n","epoch 20/100 return: 204.34884302169263\n","epoch 30/100 return: -3.3447185387926766\n","epoch 40/100 return: 240.50859207630464\n","epoch 50/100 return: 261.640101689585\n","epoch 60/100 return: 26.612026486514253\n","epoch 70/100 return: 231.18043859883346\n","epoch 80/100 return: 290.57065540539577\n","epoch 90/100 return: 259.11340249864315\n","###############    Reward for test environment for run 15: 180.867415550399.   ###############\n","\n","\n","Average reward for 10 repetitions: 160.0442169528039\n","ALL RESULTS TRAIL: [160.0442169528039]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum64', 'NUM_TRAJS_GIVEN': 64, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 64, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4878973364830017, entropy -0.34097230434417725, env classifier loss 0.650961697101593\tepoch 0/100 return: 251.6936774191984\n","epoch 10/100 return: 201.0262399514719\n","epoch 20/100 return: 256.69217666892814\n","epoch 30/100 return: 215.37146925478763\n","epoch 40/100 return: -633.8271239471976\n","epoch 50/100 return: -10.618414504279652\n","epoch 60/100 return: 274.44398353643805\n","epoch 70/100 return: 125.28206632924037\n","epoch 80/100 return: 283.2240353540992\n","epoch 90/100 return: 263.90162854247353\n","###############    Reward for test environment for run 1: 179.06832467368054.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4511025547981262, entropy -0.33921968936920166, env classifier loss 0.6418727040290833\tepoch 0/100 return: 271.01618501691837\n","epoch 10/100 return: 281.3976150382815\n","epoch 20/100 return: -46.26532505895676\n","epoch 30/100 return: 282.8906062177879\n","epoch 40/100 return: 213.55979876550947\n","epoch 50/100 return: 290.3952773647095\n","epoch 60/100 return: 37.90424010283604\n","epoch 70/100 return: 271.2055954645401\n","epoch 80/100 return: 280.31516286944134\n","epoch 90/100 return: 255.09475010323587\n","###############    Reward for test environment for run 2: 213.39405927096703.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.328971803188324, entropy -0.3414725065231323, env classifier loss 0.7102470993995667\tepoch 0/100 return: 194.6348255140782\n","epoch 10/100 return: 96.16408239175557\n","epoch 20/100 return: 217.0230895566736\n","epoch 30/100 return: 235.73355442713006\n","epoch 40/100 return: 208.58180684498757\n","epoch 50/100 return: 81.49095523922503\n","epoch 60/100 return: 234.28348136303782\n","epoch 70/100 return: -78.21699767106817\n","epoch 80/100 return: 212.202775235338\n","epoch 90/100 return: 93.70269006321098\n","###############    Reward for test environment for run 3: 159.41290670885957.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.50877445936203, entropy -0.3421393632888794, env classifier loss 0.6800740361213684\tepoch 0/100 return: 124.0443953757263\n","epoch 10/100 return: 272.98661456754905\n","epoch 20/100 return: 257.5775768225557\n","epoch 30/100 return: 249.1522885284076\n","epoch 40/100 return: 227.64965606954735\n","epoch 50/100 return: 287.2891514893092\n","epoch 60/100 return: 253.04786010247838\n","epoch 70/100 return: 230.60867409763958\n","epoch 80/100 return: 253.35068453989805\n","epoch 90/100 return: 276.01142806703496\n","###############    Reward for test environment for run 4: 213.66249122262087.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4629553556442261, entropy -0.33741819858551025, env classifier loss 0.7111948132514954\tepoch 0/100 return: 81.75606593882046\n","epoch 10/100 return: 253.78710103017184\n","epoch 20/100 return: -548.6785146567466\n","epoch 30/100 return: 258.9383242358067\n","epoch 40/100 return: 108.55315448649534\n","epoch 50/100 return: 285.2975627751912\n","epoch 60/100 return: 254.04502388060513\n","epoch 70/100 return: 51.035389848526364\n","epoch 80/100 return: 207.05082628729218\n","epoch 90/100 return: 230.6849381614331\n","###############    Reward for test environment for run 5: 174.76723371482933.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.49000677466392517, entropy -0.3398185670375824, env classifier loss 0.6673009991645813\tepoch 0/100 return: 245.10889617171216\n","epoch 10/100 return: 276.798346314617\n","epoch 20/100 return: 275.70477572118534\n","epoch 30/100 return: 272.4515933942761\n","epoch 40/100 return: 248.0877245880706\n","epoch 50/100 return: 276.23788364223276\n","epoch 60/100 return: 277.37418857085504\n","epoch 70/100 return: 258.46795084297446\n","epoch 80/100 return: 155.75132309938328\n","epoch 90/100 return: 259.84996263950455\n","###############    Reward for test environment for run 6: 228.02687693727893.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5231599807739258, entropy -0.3373350501060486, env classifier loss 0.6367943286895752\tepoch 0/100 return: 272.04999963700607\n","epoch 10/100 return: 262.5490967347031\n","epoch 20/100 return: 277.73021448151457\n","epoch 30/100 return: 262.92927845444217\n","epoch 40/100 return: 255.94944634316744\n","epoch 50/100 return: 244.8421299457404\n","epoch 60/100 return: 253.195230145787\n","epoch 70/100 return: 230.0693107743904\n","epoch 80/100 return: 254.21396773758164\n","epoch 90/100 return: 257.61729599394795\n","###############    Reward for test environment for run 7: 240.62398067478972.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.550116777420044, entropy -0.3332453966140747, env classifier loss 0.7584498524665833\tepoch 0/100 return: 38.22617764777456\n","epoch 10/100 return: 17.363559280274345\n","epoch 20/100 return: 23.974964787762886\n","epoch 30/100 return: -13.371031818103209\n","epoch 40/100 return: 31.61941926480131\n","epoch 50/100 return: -52.153142380912975\n","epoch 60/100 return: 60.467823548683356\n","epoch 70/100 return: -1.3230029043980167\n","epoch 80/100 return: -72.4612720473795\n","epoch 90/100 return: -5.689332066553882\n","###############    Reward for test environment for run 8: -10.556621089648118.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5035247206687927, entropy -0.34221330285072327, env classifier loss 0.7339220643043518\tepoch 0/100 return: 35.61398201110623\n","epoch 10/100 return: 28.57440098565732\n","epoch 20/100 return: 18.055330006755526\n","epoch 30/100 return: 53.81784774881936\n","epoch 40/100 return: 208.23033191269278\n","epoch 50/100 return: 43.94949725387374\n","epoch 60/100 return: 50.54522956134574\n","epoch 70/100 return: 56.872878237604276\n","epoch 80/100 return: 131.3748475612267\n","epoch 90/100 return: 44.72959357334055\n","###############    Reward for test environment for run 9: 37.53621376016266.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.6408310532569885, entropy -0.3424339294433594, env classifier loss 0.665372908115387\tepoch 0/100 return: -177.2524185825917\n","epoch 10/100 return: -267.2691857832341\n","epoch 20/100 return: 242.67047387819753\n","epoch 30/100 return: -214.97271979067\n","epoch 40/100 return: 185.80375613272216\n","epoch 50/100 return: -441.01504649664287\n","epoch 60/100 return: 202.3392079671895\n","epoch 70/100 return: 108.52433552328277\n","epoch 80/100 return: 245.28669087222983\n","epoch 90/100 return: -250.11201582817117\n","###############    Reward for test environment for run 10: 129.43285689519493.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5885559320449829, entropy -0.3384148180484772, env classifier loss 0.6852911710739136\tepoch 0/100 return: 23.870659962562698\n","epoch 10/100 return: 22.411386612196114\n","epoch 20/100 return: 0.06907261166440604\n","epoch 30/100 return: -31.858599574987213\n","epoch 40/100 return: 165.22268390705216\n","epoch 50/100 return: -189.6341290896116\n","epoch 60/100 return: 34.310058989301396\n","epoch 70/100 return: -496.1446765965684\n","epoch 80/100 return: 6.754668340807859\n","epoch 90/100 return: 20.73718477145441\n","###############    Reward for test environment for run 11: 3.3198674060197506.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.3245154917240143, entropy -0.3383990526199341, env classifier loss 0.6537634134292603\tepoch 0/100 return: 56.90246973240385\n","epoch 10/100 return: 234.84907735243638\n","epoch 20/100 return: 267.54514833979584\n","epoch 30/100 return: 256.5741650871685\n","epoch 40/100 return: 59.238684565134164\n","epoch 50/100 return: 200.7408464462437\n","epoch 60/100 return: 212.95567128517433\n","epoch 70/100 return: 52.44332823140693\n","epoch 80/100 return: 228.78828437784222\n","epoch 90/100 return: 248.12934326683265\n","###############    Reward for test environment for run 12: 128.91479875796742.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.34256941080093384, entropy -0.34071943163871765, env classifier loss 0.6512572169303894\tepoch 0/100 return: 239.83152428762202\n","epoch 10/100 return: 271.39289007628895\n","epoch 20/100 return: 281.72142887247935\n","epoch 30/100 return: 13.325232798697755\n","epoch 40/100 return: 225.06942627915606\n","epoch 50/100 return: 229.37964193560637\n","epoch 60/100 return: 256.55024323165424\n","epoch 70/100 return: 280.33750082770456\n","epoch 80/100 return: 266.05801905707244\n","epoch 90/100 return: 223.03065830940113\n","###############    Reward for test environment for run 13: 234.99034060529775.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4037305414676666, entropy -0.3413987457752228, env classifier loss 0.6806496381759644\tepoch 0/100 return: 294.95960148901975\n","epoch 10/100 return: 266.2596162602578\n","epoch 20/100 return: 238.46101295848905\n","epoch 30/100 return: 291.57579023640153\n","epoch 40/100 return: 285.3119829852309\n","epoch 50/100 return: -269.9218780206387\n","epoch 60/100 return: 233.0390312150011\n","epoch 70/100 return: 262.8724295120866\n","epoch 80/100 return: 258.5597339870265\n","epoch 90/100 return: 244.52523795556263\n","###############    Reward for test environment for run 14: 230.40702873542108.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5879867076873779, entropy -0.344075083732605, env classifier loss 0.6953036785125732\tepoch 0/100 return: 290.89573088900886\n","epoch 10/100 return: -23.54310836955786\n","epoch 20/100 return: 303.76413476622645\n","epoch 30/100 return: 247.13381081610504\n","epoch 40/100 return: 298.0773729461088\n","epoch 50/100 return: 208.53356414198652\n","epoch 60/100 return: -9.98254429541494\n","epoch 70/100 return: 274.178765957271\n","epoch 80/100 return: 285.99259435040767\n","epoch 90/100 return: -22.710377026909974\n","###############    Reward for test environment for run 15: 145.25203179527102.   ###############\n","\n","\n","Average reward for 10 repetitions: 153.88349267124747\n","ALL RESULTS TRAIL: [153.88349267124747]\n","Config: {'ENV': 'LunarLander-v2', 'ALG': 'FINAL_APR25_BCINVStudent_replicatedata_trajnum128', 'NUM_TRAJS_GIVEN': 128, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 128, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  LunarLander-v2\n","Run 1 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.6716816425323486, entropy -0.3376871943473816, env classifier loss 0.724259614944458\tepoch 0/100 return: 20.46842691527545\n","epoch 10/100 return: 186.78359955336424\n","epoch 20/100 return: 74.7062036404139\n","epoch 30/100 return: 259.65109848462856\n","epoch 40/100 return: 221.67017570329924\n","epoch 50/100 return: 70.36666609537825\n","epoch 60/100 return: 184.93074713477526\n","epoch 70/100 return: 64.86499691700219\n","epoch 80/100 return: -11.396230226774426\n","epoch 90/100 return: 200.07511409515172\n","###############    Reward for test environment for run 1: 103.37759732058417.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.512834906578064, entropy -0.34017717838287354, env classifier loss 0.6634722352027893\tepoch 0/100 return: 287.7741913522576\n","epoch 10/100 return: 274.182001765784\n","epoch 20/100 return: 252.07356135857165\n","epoch 30/100 return: 270.0169839666522\n","epoch 40/100 return: 262.9683134223713\n","epoch 50/100 return: 210.83614502291806\n","epoch 60/100 return: 247.64821662861422\n","epoch 70/100 return: 255.52265311365306\n","epoch 80/100 return: 267.1213068149915\n","epoch 90/100 return: 246.01686689761834\n","###############    Reward for test environment for run 2: 237.36026236910197.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5370838046073914, entropy -0.3326391577720642, env classifier loss 0.6735185980796814\tepoch 0/100 return: 71.91217415382489\n","epoch 10/100 return: 78.85279246594385\n","epoch 20/100 return: 19.180607145762792\n","epoch 30/100 return: 262.81016052602206\n","epoch 40/100 return: 82.08890037207335\n","epoch 50/100 return: 79.85081570796171\n","epoch 60/100 return: -1.2469971031143743\n","epoch 70/100 return: 80.56220152583043\n","epoch 80/100 return: -19.384867939388567\n","epoch 90/100 return: -54.33113363851072\n","###############    Reward for test environment for run 3: 88.76978617338442.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.6178947687149048, entropy -0.33616894483566284, env classifier loss 0.6548012495040894\tepoch 0/100 return: 245.47552552087797\n","epoch 10/100 return: 141.51722812605658\n","epoch 20/100 return: 141.59333113608693\n","epoch 30/100 return: 73.90411850320862\n","epoch 40/100 return: 291.43180486215533\n","epoch 50/100 return: 277.0791031486386\n","epoch 60/100 return: 240.92866626585032\n","epoch 70/100 return: 245.09163908163433\n","epoch 80/100 return: 261.69670445432484\n","epoch 90/100 return: 278.6978265510789\n","###############    Reward for test environment for run 4: 214.9897340273231.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.38688716292381287, entropy -0.3376561999320984, env classifier loss 0.7557672262191772\tepoch 0/100 return: 29.7742029653586\n","epoch 10/100 return: 31.920492537930723\n","epoch 20/100 return: 28.70124055836352\n","epoch 30/100 return: 25.14526105549657\n","epoch 40/100 return: 45.56679820975463\n","epoch 50/100 return: 83.35549211808498\n","epoch 60/100 return: 26.181150576899242\n","epoch 70/100 return: 67.52312136237283\n","epoch 80/100 return: -178.06792341881942\n","epoch 90/100 return: 123.71805847702758\n","###############    Reward for test environment for run 5: 55.04463207709601.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4413272440433502, entropy -0.32660526037216187, env classifier loss 0.7028538584709167\tepoch 0/100 return: 261.3775057397114\n","epoch 10/100 return: 245.1620358918574\n","epoch 20/100 return: 262.5806028542793\n","epoch 30/100 return: 248.2575993868667\n","epoch 40/100 return: 240.37028981117678\n","epoch 50/100 return: 230.66888348214613\n","epoch 60/100 return: 241.5382272256157\n","epoch 70/100 return: 251.76843989430014\n","epoch 80/100 return: 232.61498669421312\n","epoch 90/100 return: 272.33041199118384\n","###############    Reward for test environment for run 6: 222.02276018094614.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.4079955220222473, entropy -0.33969712257385254, env classifier loss 0.6776703596115112\tepoch 0/100 return: 211.68019954930838\n","epoch 10/100 return: 91.23467839714428\n","epoch 20/100 return: 244.90188655986267\n","epoch 30/100 return: -380.1776740429105\n","epoch 40/100 return: 274.6102401797624\n","epoch 50/100 return: 158.07409488882115\n","epoch 60/100 return: 16.640816991238726\n","epoch 70/100 return: 280.35801019775914\n","epoch 80/100 return: 41.908563686838605\n","epoch 90/100 return: 73.49573654867714\n","###############    Reward for test environment for run 7: 131.79900201999567.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.6842905879020691, entropy -0.3364453911781311, env classifier loss 0.721115231513977\tepoch 0/100 return: 266.6376180894432\n","epoch 10/100 return: 248.33850771508853\n","epoch 20/100 return: 228.28890409375117\n","epoch 30/100 return: 268.6134654330791\n","epoch 40/100 return: 263.19609009014044\n","epoch 50/100 return: 241.0967070552852\n","epoch 60/100 return: 245.21895291617886\n","epoch 70/100 return: 41.1454891783776\n","epoch 80/100 return: 253.5592486956133\n","epoch 90/100 return: 251.11674928165706\n","###############    Reward for test environment for run 8: 230.57368284754298.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.6348325610160828, entropy -0.328639417886734, env classifier loss 0.7930691838264465\tepoch 0/100 return: 195.00833335144983\n","epoch 10/100 return: 61.332357132380096\n","epoch 20/100 return: 49.03031703878199\n","epoch 30/100 return: 152.45301194005654\n","epoch 40/100 return: -30.808846412842623\n","epoch 50/100 return: 46.48852169113458\n","epoch 60/100 return: 1.1964736595591647\n","epoch 70/100 return: 38.93313427466372\n","epoch 80/100 return: 193.49896174397367\n","epoch 90/100 return: 76.2669303110243\n","###############    Reward for test environment for run 9: 75.29024018808197.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5428097248077393, entropy -0.3424268960952759, env classifier loss 0.7085816860198975\tepoch 0/100 return: 247.97361379763552\n","epoch 10/100 return: 245.36773017237573\n","epoch 20/100 return: 271.30745688565696\n","epoch 30/100 return: 223.18343553486616\n","epoch 40/100 return: 215.62247633068677\n","epoch 50/100 return: 54.42696947287766\n","epoch 60/100 return: 261.4979504484003\n","epoch 70/100 return: 262.61974887869184\n","epoch 80/100 return: 14.810281248759765\n","epoch 90/100 return: 258.00296793642383\n","###############    Reward for test environment for run 10: 183.46057566931748.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5103188753128052, entropy -0.3391842842102051, env classifier loss 0.7292805910110474\tepoch 0/100 return: 179.75525340397516\n","epoch 10/100 return: 36.327687793870695\n","epoch 20/100 return: 250.88542427899472\n","epoch 30/100 return: 237.80720703737097\n","epoch 40/100 return: 281.3561102343509\n","epoch 50/100 return: 234.27220208371193\n","epoch 60/100 return: 121.49205213719358\n","epoch 70/100 return: 235.9080016152923\n","epoch 80/100 return: -7.786452453511345\n","epoch 90/100 return: 20.13446980740143\n","###############    Reward for test environment for run 11: 191.32204192101437.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5898060202598572, entropy -0.3424389958381653, env classifier loss 0.6676495671272278\tepoch 0/100 return: 3.784376516136742\n","epoch 10/100 return: 10.070488125029918\n","epoch 20/100 return: 51.13426137113785\n","epoch 30/100 return: -7.687757116039569\n","epoch 40/100 return: 59.80143471954218\n","epoch 50/100 return: 19.496444167916525\n","epoch 60/100 return: 32.06356368631349\n","epoch 70/100 return: 32.62714399772138\n","epoch 80/100 return: 21.804095999833187\n","epoch 90/100 return: 35.74731573727374\n","###############    Reward for test environment for run 12: -14.958139511219336.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.606328010559082, entropy -0.34098318219184875, env classifier loss 0.6372595429420471\tepoch 0/100 return: 143.68987612635112\n","epoch 10/100 return: 162.17198505465106\n","epoch 20/100 return: 132.40047256455196\n","epoch 30/100 return: 246.8493561266033\n","epoch 40/100 return: 272.3305984447633\n","epoch 50/100 return: 155.1757494515492\n","epoch 60/100 return: 140.15319019021945\n","epoch 70/100 return: 147.0656663509049\n","epoch 80/100 return: 30.502699933299965\n","epoch 90/100 return: 203.2048059125592\n","###############    Reward for test environment for run 13: 177.0405852760745.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.5635258555412292, entropy -0.3420957028865814, env classifier loss 0.720727264881134\tepoch 0/100 return: 0.14038607246911194\n","epoch 10/100 return: 232.58212659350824\n","epoch 20/100 return: 206.87844818228217\n","epoch 30/100 return: 51.76214634744928\n","epoch 40/100 return: 203.37556554935446\n","epoch 50/100 return: 195.0862168148168\n","epoch 60/100 return: -0.7906508668855707\n","epoch 70/100 return: 60.54574487320739\n","epoch 80/100 return: 197.56695627446595\n","epoch 90/100 return: 59.48259661832496\n","###############    Reward for test environment for run 14: 86.93389160399921.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 12\n","epoch 9000/10000, ce loss 0.7003685235977173, entropy -0.3409096896648407, env classifier loss 0.6955821514129639\tepoch 0/100 return: 245.74783737965674\n","epoch 10/100 return: 233.32253468420086\n","epoch 20/100 return: 260.247984326404\n","epoch 30/100 return: 219.86484451586853\n","epoch 40/100 return: 250.82870036641265\n","epoch 50/100 return: 231.81776324762924\n","epoch 60/100 return: 197.82015601685103\n","epoch 70/100 return: 226.4630298998992\n","epoch 80/100 return: 224.60304781462523\n","epoch 90/100 return: 226.30412098221097\n","###############    Reward for test environment for run 15: 153.91054930325802.   ###############\n","\n","\n","Average reward for 10 repetitions: 142.46248009776673\n","ALL RESULTS TRAIL: [142.46248009776673]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"GoQfSrUmlIZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"BFyOmVkElIXN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- BCINV -- Acrobot"],"metadata":{"id":"TwwOPcmdlIog"}},{"cell_type":"code","source":["config['ENV'] = 'Acrobot-v1'\n","config['METHOD'] = \"BCINV\"\n","\n","for traj_num in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","\n","    config['ALG'] = \"FINAL_APR26_BCINVStudent_replicatedata_trajnum\" + str(traj_num)\n","\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BC\"\n","    #config['ENV'] == \"CartPole-v1\"\n","    #config['ENV'] == \"LunarLander-v2\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 20\n","    #config[\"TRAJ_SHIFT\"] = 20\n","    ###############.  settings   ###############\n","\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651013933727,"user_tz":240,"elapsed":12299828,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0525c15f-3683-480d-9c79-62d9940dfe78","id":"MILLvyUGlIog"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum1', 'NUM_TRAJS_GIVEN': 1, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 1, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 2.260858451563763e-07, entropy -0.3319433033466339, env classifier loss 0.62972491979599\t\n","\n","epoch 0/100 return: -90.0\n","epoch 10/100 return: -87.0\n","epoch 20/100 return: -65.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -113.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -70.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 1: -82.86.   ###############\n","\n","\n","Run 2 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 8.181688826880418e-06, entropy -0.1575135737657547, env classifier loss 0.5288845300674438\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -97.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 2: -85.35.   ###############\n","\n","\n","Run 3 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 3.2080522942123935e-05, entropy -0.34521782398223877, env classifier loss 0.6811338067054749\t\n","\n","epoch 0/100 return: -100.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -87.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 3: -99.78.   ###############\n","\n","\n","Run 4 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 6.251550530578243e-06, entropy -0.3315573036670685, env classifier loss 0.6286897659301758\t\n","\n","epoch 0/100 return: -500.0\n","epoch 10/100 return: -500.0\n","epoch 20/100 return: -500.0\n","epoch 30/100 return: -500.0\n","epoch 40/100 return: -500.0\n","epoch 50/100 return: -500.0\n","epoch 60/100 return: -500.0\n","epoch 70/100 return: -500.0\n","epoch 80/100 return: -101.0\n","epoch 90/100 return: -500.0\n","###############    Reward for test environment for run 4: -444.21.   ###############\n","\n","\n","Run 5 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 2.545440656831488e-05, entropy -0.3427046835422516, env classifier loss 0.6689713597297668\t\n","\n","epoch 0/100 return: -281.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -181.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -115.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -96.0\n","###############    Reward for test environment for run 5: -102.9.   ###############\n","\n","\n","Run 6 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 4.534274012257811e-06, entropy -0.3177340626716614, env classifier loss 0.700267493724823\t\n","\n","epoch 0/100 return: -98.0\n","epoch 10/100 return: -102.0\n","epoch 20/100 return: -106.0\n","epoch 30/100 return: -114.0\n","epoch 40/100 return: -115.0\n","epoch 50/100 return: -97.0\n","epoch 60/100 return: -95.0\n","epoch 70/100 return: -99.0\n","epoch 80/100 return: -114.0\n","epoch 90/100 return: -104.0\n","###############    Reward for test environment for run 6: -107.91.   ###############\n","\n","\n","Run 7 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.0, entropy -0.3428694009780884, env classifier loss 0.6690750122070312\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -206.0\n","epoch 50/100 return: -93.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -94.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 7: -87.66.   ###############\n","\n","\n","Run 8 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 2.313471213710727e-06, entropy -0.3352207839488983, env classifier loss 0.6322090029716492\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -110.0\n","epoch 20/100 return: -190.0\n","epoch 30/100 return: -114.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -184.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -121.0\n","epoch 90/100 return: -93.0\n","###############    Reward for test environment for run 8: -104.92.   ###############\n","\n","\n","Run 9 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 3.5182465580874123e-06, entropy -0.32524436712265015, env classifier loss 0.6187236309051514\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -82.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 9: -86.98.   ###############\n","\n","\n","Run 10 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 8.221329395041721e-09, entropy -0.3424187898635864, env classifier loss 0.659386157989502\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -103.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 10: -85.59.   ###############\n","\n","\n","Run 11 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 5.4564101446885616e-05, entropy -0.3401505649089813, env classifier loss 0.6653059720993042\t\n","\n","epoch 0/100 return: -96.0\n","epoch 10/100 return: -121.0\n","epoch 20/100 return: -88.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -99.0\n","epoch 60/100 return: -84.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -86.0\n","###############    Reward for test environment for run 11: -117.22.   ###############\n","\n","\n","Run 12 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.0, entropy -0.34489378333091736, env classifier loss 0.6521881222724915\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -149.0\n","epoch 20/100 return: -130.0\n","epoch 30/100 return: -92.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -100.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 12: -86.09.   ###############\n","\n","\n","Run 13 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 1.5224596836560522e-06, entropy -0.34132811427116394, env classifier loss 0.6720654964447021\t\n","\n","epoch 0/100 return: -99.0\n","epoch 10/100 return: -66.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -65.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -96.0\n","epoch 70/100 return: -111.0\n","epoch 80/100 return: -100.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 13: -89.38.   ###############\n","\n","\n","Run 14 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.0023534921929240227, entropy -0.24254679679870605, env classifier loss 0.7272286415100098\t\n","\n","epoch 0/100 return: -500.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -97.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -95.0\n","epoch 60/100 return: -100.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -66.0\n","epoch 90/100 return: -347.0\n","###############    Reward for test environment for run 14: -143.35.   ###############\n","\n","\n","Run 15 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 8.983261068351567e-05, entropy -0.3412414491176605, env classifier loss 0.6785938739776611\t\n","\n","epoch 0/100 return: -66.0\n","epoch 10/100 return: -66.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -233.0\n","epoch 60/100 return: -108.0\n","epoch 70/100 return: -66.0\n","epoch 80/100 return: -135.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 15: -88.5.   ###############\n","\n","\n","Average reward for 10 repetitions: -120.84666666666665\n","ALL RESULTS TRAIL: [-120.84666666666665]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum2', 'NUM_TRAJS_GIVEN': 2, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 2, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 3.486925925244577e-05, entropy -0.31676948070526123, env classifier loss 0.7388288974761963\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -80.0\n","epoch 40/100 return: -75.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 1: -88.33.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0002626648056320846, entropy -0.34386858344078064, env classifier loss 0.6666498184204102\t\n","\n","epoch 0/100 return: -145.0\n","epoch 10/100 return: -95.0\n","epoch 20/100 return: -97.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -96.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -88.0\n","###############    Reward for test environment for run 2: -82.6.   ###############\n","\n","\n","Run 3 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.00015903959865681827, entropy -0.34453776478767395, env classifier loss 0.6750124096870422\t\n","\n","epoch 0/100 return: -83.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -88.0\n","epoch 30/100 return: -83.0\n","epoch 40/100 return: -102.0\n","epoch 50/100 return: -100.0\n","epoch 60/100 return: -83.0\n","epoch 70/100 return: -130.0\n","epoch 80/100 return: -83.0\n","epoch 90/100 return: -118.0\n","###############    Reward for test environment for run 3: -102.64.   ###############\n","\n","\n","Run 4 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 5.535658056032844e-05, entropy -0.3434721827507019, env classifier loss 0.6772753000259399\t\n","\n","epoch 0/100 return: -104.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 4: -85.94.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.001653548562899232, entropy -0.33549368381500244, env classifier loss 0.6460099816322327\t\n","\n","epoch 0/100 return: -69.0\n","epoch 10/100 return: -81.0\n","epoch 20/100 return: -106.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -69.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 5: -83.03.   ###############\n","\n","\n","Run 6 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.0006303899572230875, entropy -0.34086814522743225, env classifier loss 0.6419939398765564\t\n","\n","epoch 0/100 return: -101.0\n","epoch 10/100 return: -94.0\n","epoch 20/100 return: -128.0\n","epoch 30/100 return: -112.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -87.0\n","epoch 60/100 return: -120.0\n","epoch 70/100 return: -120.0\n","epoch 80/100 return: -112.0\n","epoch 90/100 return: -93.0\n","###############    Reward for test environment for run 6: -104.13.   ###############\n","\n","\n","Run 7 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.0001314178662141785, entropy -0.33875393867492676, env classifier loss 0.6347483396530151\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 7: -84.25.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00013003898493479937, entropy -0.34166812896728516, env classifier loss 0.6520087718963623\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -81.0\n","###############    Reward for test environment for run 8: -88.98.   ###############\n","\n","\n","Run 9 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.00021814725187141448, entropy -0.3304070234298706, env classifier loss 0.7053754329681396\t\n","\n","epoch 0/100 return: -93.0\n","epoch 10/100 return: -156.0\n","epoch 20/100 return: -68.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -135.0\n","epoch 50/100 return: -112.0\n","epoch 60/100 return: -98.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -82.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 9: -113.82.   ###############\n","\n","\n","Run 10 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.00011432311293901876, entropy -0.34561780095100403, env classifier loss 0.6900824904441833\t\n","\n","epoch 0/100 return: -214.0\n","epoch 10/100 return: -422.0\n","epoch 20/100 return: -386.0\n","epoch 30/100 return: -500.0\n","epoch 40/100 return: -379.0\n","epoch 50/100 return: -500.0\n","epoch 60/100 return: -286.0\n","epoch 70/100 return: -264.0\n","epoch 80/100 return: -256.0\n","epoch 90/100 return: -381.0\n","###############    Reward for test environment for run 10: -381.44.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.833230822347105e-05, entropy -0.3447761535644531, env classifier loss 0.6848825216293335\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -66.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -104.0\n","epoch 90/100 return: -81.0\n","###############    Reward for test environment for run 11: -88.66.   ###############\n","\n","\n","Run 12 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 0.09575928002595901, entropy -0.3404763638973236, env classifier loss 0.6683130860328674\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -87.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -106.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 12: -81.72.   ###############\n","\n","\n","Run 13 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 1.3511502402252518e-05, entropy -0.34586548805236816, env classifier loss 0.6844739317893982\t\n","\n","epoch 0/100 return: -67.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -65.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -95.0\n","###############    Reward for test environment for run 13: -81.54.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.5440956531165284e-06, entropy -0.3457355499267578, env classifier loss 0.6872838139533997\t\n","\n","epoch 0/100 return: -172.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -116.0\n","epoch 30/100 return: -178.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -151.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -88.0\n","###############    Reward for test environment for run 14: -94.78.   ###############\n","\n","\n","Run 15 out of 15\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 9000/10000, ce loss 4.689862544182688e-05, entropy -0.3398909568786621, env classifier loss 0.666392982006073\t\n","\n","epoch 0/100 return: -66.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -99.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 15: -80.17.   ###############\n","\n","\n","Average reward for 10 repetitions: -109.46866666666668\n","ALL RESULTS TRAIL: [-109.46866666666668]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum3', 'NUM_TRAJS_GIVEN': 3, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 3, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00019141481607221067, entropy -0.34596899151802063, env classifier loss 0.6897306442260742\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -70.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -74.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -93.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -162.0\n","###############    Reward for test environment for run 1: -86.89.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00023741685436107218, entropy -0.34517979621887207, env classifier loss 0.6911906599998474\t\n","\n","epoch 0/100 return: -107.0\n","epoch 10/100 return: -116.0\n","epoch 20/100 return: -335.0\n","epoch 30/100 return: -147.0\n","epoch 40/100 return: -108.0\n","epoch 50/100 return: -170.0\n","epoch 60/100 return: -115.0\n","epoch 70/100 return: -135.0\n","epoch 80/100 return: -116.0\n","epoch 90/100 return: -99.0\n","###############    Reward for test environment for run 2: -141.69.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.803492265637033e-05, entropy -0.3440417945384979, env classifier loss 0.7073635458946228\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -116.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -70.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -208.0\n","###############    Reward for test environment for run 3: -85.59.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 7.158995140343904e-05, entropy -0.3460977375507355, env classifier loss 0.6954775452613831\t\n","\n","epoch 0/100 return: -135.0\n","epoch 10/100 return: -155.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -69.0\n","epoch 60/100 return: -70.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -88.0\n","###############    Reward for test environment for run 4: -86.44.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.0212711862986907e-05, entropy -0.34522581100463867, env classifier loss 0.7000197768211365\t\n","\n","epoch 0/100 return: -92.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -66.0\n","epoch 50/100 return: -87.0\n","epoch 60/100 return: -152.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 5: -87.03.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.000630012946203351, entropy -0.3447064757347107, env classifier loss 0.6957469582557678\t\n","\n","epoch 0/100 return: -110.0\n","epoch 10/100 return: -109.0\n","epoch 20/100 return: -225.0\n","epoch 30/100 return: -107.0\n","epoch 40/100 return: -108.0\n","epoch 50/100 return: -99.0\n","epoch 60/100 return: -108.0\n","epoch 70/100 return: -159.0\n","epoch 80/100 return: -149.0\n","epoch 90/100 return: -109.0\n","###############    Reward for test environment for run 6: -109.38.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00012423243606463075, entropy -0.3461150527000427, env classifier loss 0.6875172257423401\t\n","\n","epoch 0/100 return: -65.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -93.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -86.0\n","epoch 60/100 return: -98.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -100.0\n","epoch 90/100 return: -95.0\n","###############    Reward for test environment for run 7: -81.79.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0004384720232337713, entropy -0.3446688652038574, env classifier loss 0.6807727813720703\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -122.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -115.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -127.0\n","epoch 80/100 return: -94.0\n","epoch 90/100 return: -82.0\n","###############    Reward for test environment for run 8: -96.88.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00020158826373517513, entropy -0.34401047229766846, env classifier loss 0.6913819313049316\t\n","\n","epoch 0/100 return: -155.0\n","epoch 10/100 return: -148.0\n","epoch 20/100 return: -163.0\n","epoch 30/100 return: -167.0\n","epoch 40/100 return: -175.0\n","epoch 50/100 return: -147.0\n","epoch 60/100 return: -171.0\n","epoch 70/100 return: -144.0\n","epoch 80/100 return: -183.0\n","epoch 90/100 return: -146.0\n","###############    Reward for test environment for run 9: -190.63.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00019000188331119716, entropy -0.3450027108192444, env classifier loss 0.6973159313201904\t\n","\n","epoch 0/100 return: -133.0\n","epoch 10/100 return: -85.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -176.0\n","epoch 40/100 return: -197.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 10: -87.06.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.646401455625892e-05, entropy -0.3427632451057434, env classifier loss 0.6948253512382507\t\n","\n","epoch 0/100 return: -70.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -88.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -80.0\n","###############    Reward for test environment for run 11: -103.57.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 6.123985804151744e-05, entropy -0.34553301334381104, env classifier loss 0.6785253882408142\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -69.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -114.0\n","epoch 60/100 return: -69.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -105.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 12: -85.46.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0005206011119298637, entropy -0.33010679483413696, env classifier loss 0.6909286379814148\t\n","\n","epoch 0/100 return: -86.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -106.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 13: -86.65.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.492688357364386e-05, entropy -0.3446437418460846, env classifier loss 0.6690032482147217\t\n","\n","epoch 0/100 return: -131.0\n","epoch 10/100 return: -169.0\n","epoch 20/100 return: -161.0\n","epoch 30/100 return: -162.0\n","epoch 40/100 return: -148.0\n","epoch 50/100 return: -310.0\n","epoch 60/100 return: -143.0\n","epoch 70/100 return: -145.0\n","epoch 80/100 return: -189.0\n","epoch 90/100 return: -146.0\n","###############    Reward for test environment for run 14: -168.93.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 9.778006642591208e-05, entropy -0.34570008516311646, env classifier loss 0.693102240562439\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -143.0\n","epoch 40/100 return: -75.0\n","epoch 50/100 return: -104.0\n","epoch 60/100 return: -97.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 15: -87.45.   ###############\n","\n","\n","Average reward for 10 repetitions: -105.69600000000001\n","ALL RESULTS TRAIL: [-105.69600000000001]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum4', 'NUM_TRAJS_GIVEN': 4, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 4, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 2.771559957182035e-05, entropy -0.34554722905158997, env classifier loss 0.6876598000526428\t\n","\n","epoch 0/100 return: -69.0\n","epoch 10/100 return: -96.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -125.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -66.0\n","###############    Reward for test environment for run 1: -80.31.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00042149756336584687, entropy -0.32689714431762695, env classifier loss 0.7243868112564087\t\n","\n","epoch 0/100 return: -110.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -88.0\n","epoch 40/100 return: -109.0\n","epoch 50/100 return: -97.0\n","epoch 60/100 return: -139.0\n","epoch 70/100 return: -136.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 2: -108.65.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0009091580286622047, entropy -0.3440490961074829, env classifier loss 0.6764093637466431\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -67.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -86.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 3: -84.47.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.931828582106391e-06, entropy -0.3461506962776184, env classifier loss 0.6910732984542847\t\n","\n","epoch 0/100 return: -88.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -69.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 4: -81.48.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00013541392399929464, entropy -0.3447577953338623, env classifier loss 0.6838279366493225\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -98.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 5: -90.97.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.984727532544639e-05, entropy -0.34584224224090576, env classifier loss 0.6998667120933533\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -108.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 6: -84.16.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.74325570394285e-05, entropy -0.3441789746284485, env classifier loss 0.7067212462425232\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -250.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -75.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -100.0\n","epoch 90/100 return: -101.0\n","###############    Reward for test environment for run 7: -85.91.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00035106026916764677, entropy -0.3456916809082031, env classifier loss 0.6915198564529419\t\n","\n","epoch 0/100 return: -89.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -122.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -113.0\n","epoch 60/100 return: -131.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 8: -150.09.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00012439623242244124, entropy -0.3459411561489105, env classifier loss 0.6924090385437012\t\n","\n","epoch 0/100 return: -96.0\n","epoch 10/100 return: -107.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -75.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -101.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -96.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 9: -93.08.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.2449868336261716e-05, entropy -0.3454331159591675, env classifier loss 0.6862116456031799\t\n","\n","epoch 0/100 return: -115.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -84.0\n","epoch 50/100 return: -101.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -66.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -105.0\n","###############    Reward for test environment for run 10: -87.15.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0006548741948790848, entropy -0.34429335594177246, env classifier loss 0.6770434975624084\t\n","\n","epoch 0/100 return: -144.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -115.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -86.0\n","epoch 80/100 return: -69.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 11: -84.53.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0008380046347156167, entropy -0.3445751965045929, env classifier loss 0.6965248584747314\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -204.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -94.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -94.0\n","epoch 70/100 return: -100.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 12: -87.2.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.747934483224526e-05, entropy -0.34189504384994507, env classifier loss 0.6957873702049255\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -86.0\n","epoch 40/100 return: -105.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 13: -82.26.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00011641195305855945, entropy -0.3442222476005554, env classifier loss 0.688336193561554\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -154.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -100.0\n","epoch 40/100 return: -102.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -114.0\n","epoch 80/100 return: -143.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 14: -91.6.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.957022221991792e-05, entropy -0.3454974889755249, env classifier loss 0.681631863117218\t\n","\n","epoch 0/100 return: -90.0\n","epoch 10/100 return: -82.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -87.0\n","epoch 60/100 return: -134.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 15: -85.91.   ###############\n","\n","\n","Average reward for 10 repetitions: -91.85133333333333\n","ALL RESULTS TRAIL: [-91.85133333333333]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum5', 'NUM_TRAJS_GIVEN': 5, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 5, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0, entropy -0.34204167127609253, env classifier loss 0.6839562058448792\t\n","\n","epoch 0/100 return: -104.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -82.0\n","epoch 30/100 return: -96.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -138.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -121.0\n","epoch 90/100 return: -107.0\n","###############    Reward for test environment for run 1: -88.58.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.546611206838861e-05, entropy -0.34592342376708984, env classifier loss 0.6882138252258301\t\n","\n","epoch 0/100 return: -99.0\n","epoch 10/100 return: -113.0\n","epoch 20/100 return: -82.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -82.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -69.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 2: -90.05.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.05929926037788391, entropy -0.34433168172836304, env classifier loss 0.7138803601264954\t\n","\n","epoch 0/100 return: -64.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -130.0\n","epoch 40/100 return: -83.0\n","epoch 50/100 return: -97.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 3: -83.1.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.674740582937375e-05, entropy -0.3437533974647522, env classifier loss 0.6824472546577454\t\n","\n","epoch 0/100 return: -87.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -82.0\n","###############    Reward for test environment for run 4: -90.23.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0004548788128886372, entropy -0.34532594680786133, env classifier loss 0.688620924949646\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -69.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -108.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 5: -83.27.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.479198807734065e-05, entropy -0.3446069359779358, env classifier loss 0.6785836815834045\t\n","\n","epoch 0/100 return: -95.0\n","epoch 10/100 return: -64.0\n","epoch 20/100 return: -65.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -94.0\n","epoch 70/100 return: -64.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 6: -81.3.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.07708648708649e-06, entropy -0.34513962268829346, env classifier loss 0.6890686750411987\t\n","\n","epoch 0/100 return: -70.0\n","epoch 10/100 return: -98.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -82.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -75.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -89.0\n","epoch 90/100 return: -159.0\n","###############    Reward for test environment for run 7: -86.49.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.3679538319120184e-05, entropy -0.34461551904678345, env classifier loss 0.6907200813293457\t\n","\n","epoch 0/100 return: -69.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -100.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -82.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -93.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 8: -81.37.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.570314922602847e-05, entropy -0.3450034260749817, env classifier loss 0.6926183700561523\t\n","\n","epoch 0/100 return: -126.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -66.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -83.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -66.0\n","###############    Reward for test environment for run 9: -90.98.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.3334962204680778e-05, entropy -0.3457615375518799, env classifier loss 0.6685380935668945\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -96.0\n","epoch 30/100 return: -82.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -96.0\n","epoch 70/100 return: -104.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 10: -83.41.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.0426355806412175e-05, entropy -0.344494104385376, env classifier loss 0.6766489148139954\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 11: -84.44.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00010999782534781843, entropy -0.3438882827758789, env classifier loss 0.6827429533004761\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -92.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -66.0\n","epoch 60/100 return: -82.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -70.0\n","epoch 90/100 return: -120.0\n","###############    Reward for test environment for run 12: -82.38.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 2.064407817670144e-05, entropy -0.3445534110069275, env classifier loss 0.6892620921134949\t\n","\n","epoch 0/100 return: -76.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -121.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -98.0\n","###############    Reward for test environment for run 13: -88.3.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00038780621252954006, entropy -0.34513673186302185, env classifier loss 0.6854325532913208\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -187.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -82.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -83.0\n","###############    Reward for test environment for run 14: -84.24.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00015283332322724164, entropy -0.34515485167503357, env classifier loss 0.6847769618034363\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -69.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -81.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 15: -81.24.   ###############\n","\n","\n","Average reward for 10 repetitions: -85.29199999999999\n","ALL RESULTS TRAIL: [-85.29199999999999]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum6', 'NUM_TRAJS_GIVEN': 6, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 6, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.478952152770944e-05, entropy -0.3441815674304962, env classifier loss 0.7054133415222168\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -92.0\n","epoch 30/100 return: -167.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -66.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -66.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 1: -85.2.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.02508351393043995, entropy -0.34238380193710327, env classifier loss 0.6700800061225891\t\n","\n","epoch 0/100 return: -130.0\n","epoch 10/100 return: -70.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -67.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 2: -87.06.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 9.613019210519269e-05, entropy -0.344731867313385, env classifier loss 0.6872567534446716\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -103.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -102.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -105.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 3: -84.53.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.013888144865632057, entropy -0.34503477811813354, env classifier loss 0.6892656683921814\t\n","\n","epoch 0/100 return: -92.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -83.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -171.0\n","###############    Reward for test environment for run 4: -86.68.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0001869639236247167, entropy -0.3460426926612854, env classifier loss 0.6842023134231567\t\n","\n","epoch 0/100 return: -86.0\n","epoch 10/100 return: -83.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -161.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -102.0\n","###############    Reward for test environment for run 5: -89.07.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 2.4693224986549467e-05, entropy -0.34593817591667175, env classifier loss 0.6907027363777161\t\n","\n","epoch 0/100 return: -80.0\n","epoch 10/100 return: -182.0\n","epoch 20/100 return: -82.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -94.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -70.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -105.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 6: -87.23.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0003169415576849133, entropy -0.3454444408416748, env classifier loss 0.6969316005706787\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -108.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -131.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 7: -82.87.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.05954601243138313, entropy -0.34338250756263733, env classifier loss 0.6711927056312561\t\n","\n","epoch 0/100 return: -114.0\n","epoch 10/100 return: -128.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -321.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -74.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 8: -83.89.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0002122006262652576, entropy -0.34373360872268677, env classifier loss 0.6940733790397644\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -94.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -94.0\n","epoch 60/100 return: -107.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 9: -84.61.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.2527474609669298e-05, entropy -0.34549540281295776, env classifier loss 0.6877405047416687\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -64.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -94.0\n","###############    Reward for test environment for run 10: -84.02.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0458233505487442, entropy -0.34446287155151367, env classifier loss 0.7057685256004333\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -94.0\n","epoch 20/100 return: -103.0\n","epoch 30/100 return: -95.0\n","epoch 40/100 return: -184.0\n","epoch 50/100 return: -95.0\n","epoch 60/100 return: -92.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -94.0\n","epoch 90/100 return: -126.0\n","###############    Reward for test environment for run 11: -101.86.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.845644773216918e-05, entropy -0.34645378589630127, env classifier loss 0.6916040778160095\t\n","\n","epoch 0/100 return: -92.0\n","epoch 10/100 return: -87.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -82.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -91.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 12: -84.91.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0003859239222947508, entropy -0.3463108539581299, env classifier loss 0.6879754662513733\t\n","\n","epoch 0/100 return: -88.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -142.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -217.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 13: -85.81.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.9937581934500486e-05, entropy -0.34540224075317383, env classifier loss 0.6928987503051758\t\n","\n","epoch 0/100 return: -74.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -169.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -94.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -65.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 14: -83.63.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00010176412615692243, entropy -0.34637129306793213, env classifier loss 0.6931772232055664\t\n","\n","epoch 0/100 return: -97.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -96.0\n","epoch 60/100 return: -92.0\n","epoch 70/100 return: -261.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -100.0\n","###############    Reward for test environment for run 15: -87.19.   ###############\n","\n","\n","Average reward for 10 repetitions: -86.57066666666667\n","ALL RESULTS TRAIL: [-86.57066666666667]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum7', 'NUM_TRAJS_GIVEN': 7, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 7, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 9.059605508809909e-05, entropy -0.34576159715652466, env classifier loss 0.6930164098739624\t\n","\n","epoch 0/100 return: -177.0\n","epoch 10/100 return: -100.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -153.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -189.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 1: -91.86.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.024126440286636353, entropy -0.34214311838150024, env classifier loss 0.6873953342437744\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -143.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -82.0\n","epoch 80/100 return: -104.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 2: -83.02.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.83350847591646e-05, entropy -0.3437863290309906, env classifier loss 0.6672553420066833\t\n","\n","epoch 0/100 return: -170.0\n","epoch 10/100 return: -85.0\n","epoch 20/100 return: -215.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -74.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -86.0\n","epoch 70/100 return: -91.0\n","epoch 80/100 return: -96.0\n","epoch 90/100 return: -96.0\n","###############    Reward for test environment for run 3: -94.48.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00011020353122148663, entropy -0.34592747688293457, env classifier loss 0.6982376575469971\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -192.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -66.0\n","epoch 90/100 return: -100.0\n","###############    Reward for test environment for run 4: -89.86.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0003134820726700127, entropy -0.3459053039550781, env classifier loss 0.6890231966972351\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -96.0\n","epoch 30/100 return: -97.0\n","epoch 40/100 return: -169.0\n","epoch 50/100 return: -65.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 5: -86.24.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0006251261802390218, entropy -0.34518635272979736, env classifier loss 0.7066307067871094\t\n","\n","epoch 0/100 return: -70.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -82.0\n","epoch 40/100 return: -88.0\n","epoch 50/100 return: -174.0\n","epoch 60/100 return: -70.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 6: -81.85.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0001190198163385503, entropy -0.34350326657295227, env classifier loss 0.6882500648498535\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -69.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -70.0\n","epoch 80/100 return: -70.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 7: -84.73.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.891376637620851e-06, entropy -0.34634774923324585, env classifier loss 0.6920644640922546\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -175.0\n","###############    Reward for test environment for run 8: -85.59.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 2.9498853109544143e-05, entropy -0.34496334195137024, env classifier loss 0.6896865963935852\t\n","\n","epoch 0/100 return: -100.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -97.0\n","epoch 50/100 return: -69.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -69.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 9: -82.15.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.1497140045976266e-05, entropy -0.34324631094932556, env classifier loss 0.6967886090278625\t\n","\n","epoch 0/100 return: -93.0\n","epoch 10/100 return: -64.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -93.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -95.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -124.0\n","epoch 90/100 return: -88.0\n","###############    Reward for test environment for run 10: -89.49.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00021967983047943562, entropy -0.3428139090538025, env classifier loss 0.6849948763847351\t\n","\n","epoch 0/100 return: -88.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -66.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -66.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 11: -85.42.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 4.607560640579322e-06, entropy -0.3458085060119629, env classifier loss 0.6899693012237549\t\n","\n","epoch 0/100 return: -100.0\n","epoch 10/100 return: -82.0\n","epoch 20/100 return: -114.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -66.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -113.0\n","epoch 90/100 return: -185.0\n","###############    Reward for test environment for run 12: -89.64.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0003237855271436274, entropy -0.34498369693756104, env classifier loss 0.6734440326690674\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -66.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -66.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 13: -85.9.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.08524342626333237, entropy -0.33732470870018005, env classifier loss 0.6574031710624695\t\n","\n","epoch 0/100 return: -64.0\n","epoch 10/100 return: -69.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -108.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -86.0\n","###############    Reward for test environment for run 14: -85.07.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0003223102248739451, entropy -0.34511494636535645, env classifier loss 0.6868298649787903\t\n","\n","epoch 0/100 return: -105.0\n","epoch 10/100 return: -103.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -102.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -109.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 15: -84.91.   ###############\n","\n","\n","Average reward for 10 repetitions: -86.68066666666667\n","ALL RESULTS TRAIL: [-86.68066666666667]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum8', 'NUM_TRAJS_GIVEN': 8, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 8, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.089737821137533e-05, entropy -0.34502339363098145, env classifier loss 0.689246416091919\t\n","\n","epoch 0/100 return: -65.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -193.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -66.0\n","epoch 80/100 return: -89.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 1: -85.63.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 5.425729614216834e-05, entropy -0.34458494186401367, env classifier loss 0.7071177959442139\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -90.0\n","epoch 40/100 return: -84.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -81.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 2: -84.12.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00021677078620996326, entropy -0.34394627809524536, env classifier loss 0.6820955276489258\t\n","\n","epoch 0/100 return: -86.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -70.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -66.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -152.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 3: -89.59.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00013112516899127513, entropy -0.34491389989852905, env classifier loss 0.6701403856277466\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -93.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -95.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 4: -80.93.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.001193491043522954, entropy -0.3457302749156952, env classifier loss 0.6945850849151611\t\n","\n","epoch 0/100 return: -75.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -93.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 5: -83.93.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.006511134095489979, entropy -0.34315580129623413, env classifier loss 0.7016720175743103\t\n","\n","epoch 0/100 return: -76.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 6: -83.64.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0007272219518199563, entropy -0.345364511013031, env classifier loss 0.6850799918174744\t\n","\n","epoch 0/100 return: -89.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -101.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 7: -86.83.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00022587334387935698, entropy -0.34538817405700684, env classifier loss 0.6955617666244507\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -117.0\n","epoch 30/100 return: -108.0\n","epoch 40/100 return: -93.0\n","epoch 50/100 return: -91.0\n","epoch 60/100 return: -125.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 8: -84.39.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00980989821255207, entropy -0.3459305167198181, env classifier loss 0.6794106960296631\t\n","\n","epoch 0/100 return: -65.0\n","epoch 10/100 return: -83.0\n","epoch 20/100 return: -226.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -91.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 9: -86.01.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0001339618320344016, entropy -0.3457636833190918, env classifier loss 0.6893759965896606\t\n","\n","epoch 0/100 return: -76.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -105.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -70.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -69.0\n","epoch 80/100 return: -89.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 10: -87.38.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.3359254808165133e-05, entropy -0.34617918729782104, env classifier loss 0.6936944723129272\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -70.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -97.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -93.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 11: -86.46.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00031513729481957853, entropy -0.34304264187812805, env classifier loss 0.6959229111671448\t\n","\n","epoch 0/100 return: -82.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -70.0\n","epoch 30/100 return: -80.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 12: -82.61.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 8.53789515531389e-06, entropy -0.34557682275772095, env classifier loss 0.6859820485115051\t\n","\n","epoch 0/100 return: -90.0\n","epoch 10/100 return: -85.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -92.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -97.0\n","###############    Reward for test environment for run 13: -86.68.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.021648304536938667, entropy -0.3457111120223999, env classifier loss 0.6840966939926147\t\n","\n","epoch 0/100 return: -76.0\n","epoch 10/100 return: -110.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -83.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -96.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -158.0\n","###############    Reward for test environment for run 14: -85.6.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.007025052793323994, entropy -0.34347277879714966, env classifier loss 0.6939713358879089\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -92.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -96.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 15: -81.92.   ###############\n","\n","\n","Average reward for 10 repetitions: -85.048\n","ALL RESULTS TRAIL: [-85.048]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum9', 'NUM_TRAJS_GIVEN': 9, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 9, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0025651578325778246, entropy -0.3436235189437866, env classifier loss 0.6729004383087158\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -103.0\n","epoch 30/100 return: -99.0\n","epoch 40/100 return: -66.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -66.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 1: -80.79.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.006553623825311661, entropy -0.3403547406196594, env classifier loss 0.6951404809951782\t\n","\n","epoch 0/100 return: -80.0\n","epoch 10/100 return: -100.0\n","epoch 20/100 return: -104.0\n","epoch 30/100 return: -94.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -146.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 2: -84.39.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.09271709620952606, entropy -0.3445408344268799, env classifier loss 0.6915720701217651\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 3: -82.71.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.3084625005722046, entropy -0.3438262939453125, env classifier loss 0.6887365579605103\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -94.0\n","epoch 20/100 return: -272.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 4: -88.04.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.06474562734365463, entropy -0.3308846056461334, env classifier loss 0.7053766250610352\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -91.0\n","epoch 60/100 return: -237.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 5: -87.5.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00016897870227694511, entropy -0.3454645872116089, env classifier loss 0.6990475654602051\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 6: -85.75.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00021439547708723694, entropy -0.34620076417922974, env classifier loss 0.6837561726570129\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -88.0\n","epoch 50/100 return: -94.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -116.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -66.0\n","###############    Reward for test environment for run 7: -81.52.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.0051406206912361e-05, entropy -0.34034717082977295, env classifier loss 0.7131625413894653\t\n","\n","epoch 0/100 return: -87.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -70.0\n","epoch 60/100 return: -92.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 8: -83.2.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.05257940664887428, entropy -0.3412915766239166, env classifier loss 0.6722589731216431\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -240.0\n","###############    Reward for test environment for run 9: -84.21.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 2.800850779749453e-05, entropy -0.34618163108825684, env classifier loss 0.6990265250205994\t\n","\n","epoch 0/100 return: -79.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -70.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -100.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -88.0\n","###############    Reward for test environment for run 10: -83.99.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.5539847016334534, entropy -0.3353944420814514, env classifier loss 0.7173893451690674\t\n","\n","epoch 0/100 return: -74.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -82.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -66.0\n","epoch 70/100 return: -83.0\n","epoch 80/100 return: -74.0\n","epoch 90/100 return: -100.0\n","###############    Reward for test environment for run 11: -86.08.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 1.3774555554846302e-05, entropy -0.344765841960907, env classifier loss 0.6879364252090454\t\n","\n","epoch 0/100 return: -65.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -120.0\n","###############    Reward for test environment for run 12: -86.84.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 7.107564306352288e-05, entropy -0.3439960777759552, env classifier loss 0.6945714354515076\t\n","\n","epoch 0/100 return: -83.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -103.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -82.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 13: -81.35.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.010929404757916927, entropy -0.34590697288513184, env classifier loss 0.6994929909706116\t\n","\n","epoch 0/100 return: -83.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -100.0\n","epoch 60/100 return: -125.0\n","epoch 70/100 return: -91.0\n","epoch 80/100 return: -91.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 14: -81.73.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.10123396664857864, entropy -0.3434314727783203, env classifier loss 0.7010824084281921\t\n","\n","epoch 0/100 return: -89.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -84.0\n","epoch 50/100 return: -83.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 15: -84.48.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.17200000000001\n","ALL RESULTS TRAIL: [-84.17200000000001]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum10', 'NUM_TRAJS_GIVEN': 10, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 10, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 9.023834718391299e-05, entropy -0.3449710011482239, env classifier loss 0.6843559741973877\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -64.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 1: -84.8.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.011693102307617664, entropy -0.34292301535606384, env classifier loss 0.7009353637695312\t\n","\n","epoch 0/100 return: -88.0\n","epoch 10/100 return: -107.0\n","epoch 20/100 return: -100.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -65.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -147.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 2: -83.78.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00024375009525101632, entropy -0.3455379605293274, env classifier loss 0.6896101832389832\t\n","\n","epoch 0/100 return: -81.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -81.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -83.0\n","epoch 60/100 return: -65.0\n","epoch 70/100 return: -64.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -104.0\n","###############    Reward for test environment for run 3: -81.28.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.00036904396256431937, entropy -0.3457651734352112, env classifier loss 0.6943626403808594\t\n","\n","epoch 0/100 return: -90.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -106.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -69.0\n","###############    Reward for test environment for run 4: -84.24.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0017235379200428724, entropy -0.34490716457366943, env classifier loss 0.7002062797546387\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -166.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -66.0\n","epoch 40/100 return: -99.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 5: -82.04.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.02207065559923649, entropy -0.34541767835617065, env classifier loss 0.7031351327896118\t\n","\n","epoch 0/100 return: -87.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -83.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -93.0\n","###############    Reward for test environment for run 6: -81.54.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0017527429154142737, entropy -0.3430798053741455, env classifier loss 0.7000126838684082\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 7: -81.88.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0038687260821461678, entropy -0.345219224691391, env classifier loss 0.6992598176002502\t\n","\n","epoch 0/100 return: -85.0\n","epoch 10/100 return: -83.0\n","epoch 20/100 return: -112.0\n","epoch 30/100 return: -108.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -108.0\n","epoch 60/100 return: -63.0\n","epoch 70/100 return: -104.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -168.0\n","###############    Reward for test environment for run 8: -99.23.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 3.107326847384684e-05, entropy -0.345486044883728, env classifier loss 0.6910656690597534\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -69.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -114.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 9: -84.75.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.02072739042341709, entropy -0.34564557671546936, env classifier loss 0.6809289455413818\t\n","\n","epoch 0/100 return: -102.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -69.0\n","epoch 40/100 return: -84.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -63.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -92.0\n","epoch 90/100 return: -75.0\n","###############    Reward for test environment for run 10: -83.29.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0162549689412117, entropy -0.34273695945739746, env classifier loss 0.6620854735374451\t\n","\n","epoch 0/100 return: -73.0\n","epoch 10/100 return: -156.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 11: -82.14.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0017728196689859033, entropy -0.34376251697540283, env classifier loss 0.6821525692939758\t\n","\n","epoch 0/100 return: -69.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -86.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -86.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 12: -83.46.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0009433779632672668, entropy -0.3458564281463623, env classifier loss 0.6746887564659119\t\n","\n","epoch 0/100 return: -80.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -93.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -115.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 13: -78.43.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.04141120985150337, entropy -0.34333857893943787, env classifier loss 0.6870467066764832\t\n","\n","epoch 0/100 return: -99.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -92.0\n","epoch 30/100 return: -80.0\n","epoch 40/100 return: -84.0\n","epoch 50/100 return: -94.0\n","epoch 60/100 return: -130.0\n","epoch 70/100 return: -86.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 14: -84.4.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.027197349816560745, entropy -0.34586024284362793, env classifier loss 0.6937205195426941\t\n","\n","epoch 0/100 return: -91.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -87.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -92.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 15: -84.41.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.97800000000001\n","ALL RESULTS TRAIL: [-83.97800000000001]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_APR26_BCINVStudent_replicatedata_trajnum20', 'NUM_TRAJS_GIVEN': 20, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 20, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 10000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 15, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'BCINV', 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  BCINV\n","config env =  Acrobot-v1\n","Run 1 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0384385921061039, entropy -0.3449997305870056, env classifier loss 0.6793971657752991\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -114.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -103.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -86.0\n","###############    Reward for test environment for run 1: -84.91.   ###############\n","\n","\n","Run 2 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.03796379268169403, entropy -0.34525129199028015, env classifier loss 0.6747201085090637\t\n","\n","epoch 0/100 return: -78.0\n","epoch 10/100 return: -66.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -82.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 2: -82.88.   ###############\n","\n","\n","Run 3 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.02440039999783039, entropy -0.346309632062912, env classifier loss 0.6952754259109497\t\n","\n","epoch 0/100 return: -71.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -101.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -98.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -99.0\n","epoch 90/100 return: -92.0\n","###############    Reward for test environment for run 3: -81.35.   ###############\n","\n","\n","Run 4 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.038511887192726135, entropy -0.33945009112358093, env classifier loss 0.7179657220840454\t\n","\n","epoch 0/100 return: -72.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -134.0\n","epoch 70/100 return: -83.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -86.0\n","###############    Reward for test environment for run 4: -84.73.   ###############\n","\n","\n","Run 5 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0021262115333229303, entropy -0.34329932928085327, env classifier loss 0.6714842319488525\t\n","\n","epoch 0/100 return: -82.0\n","epoch 10/100 return: -87.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -166.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -65.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 5: -81.27.   ###############\n","\n","\n","Run 6 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.07136321812868118, entropy -0.34402522444725037, env classifier loss 0.6937862038612366\t\n","\n","epoch 0/100 return: -66.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -100.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -65.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 6: -81.18.   ###############\n","\n","\n","Run 7 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.011020757257938385, entropy -0.3450601100921631, env classifier loss 0.7021507024765015\t\n","\n","epoch 0/100 return: -84.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -106.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -91.0\n","epoch 60/100 return: -278.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -98.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 7: -86.71.   ###############\n","\n","\n","Run 8 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.03499103710055351, entropy -0.34530341625213623, env classifier loss 0.6791171431541443\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -112.0\n","epoch 90/100 return: -82.0\n","###############    Reward for test environment for run 8: -88.83.   ###############\n","\n","\n","Run 9 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.14804565906524658, entropy -0.34428295493125916, env classifier loss 0.7002562880516052\t\n","\n","epoch 0/100 return: -86.0\n","epoch 10/100 return: -99.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -92.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 9: -81.86.   ###############\n","\n","\n","Run 10 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.01173400692641735, entropy -0.3425913155078888, env classifier loss 0.6900475025177002\t\n","\n","epoch 0/100 return: -89.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -86.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -84.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -81.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 10: -82.81.   ###############\n","\n","\n","Run 11 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.06580761075019836, entropy -0.3453190326690674, env classifier loss 0.6918281316757202\t\n","\n","epoch 0/100 return: -93.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -81.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -83.0\n","epoch 80/100 return: -93.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 11: -80.8.   ###############\n","\n","\n","Run 12 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.013036438263952732, entropy -0.34625372290611267, env classifier loss 0.6892986297607422\t\n","\n","epoch 0/100 return: -76.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -81.0\n","###############    Reward for test environment for run 12: -83.66.   ###############\n","\n","\n","Run 13 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.014916415326297283, entropy -0.3425481915473938, env classifier loss 0.733566403388977\t\n","\n","epoch 0/100 return: -65.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -116.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -118.0\n","epoch 90/100 return: -98.0\n","###############    Reward for test environment for run 13: -92.21.   ###############\n","\n","\n","Run 14 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.010156715288758278, entropy -0.3455171585083008, env classifier loss 0.6865999698638916\t\n","\n","epoch 0/100 return: -77.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -96.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 14: -81.4.   ###############\n","\n","\n","Run 15 out of 15\n","state_dim 10\n","epoch 9000/10000, ce loss 0.0023812218569219112, entropy -0.34526416659355164, env classifier loss 0.682395875453949\t\n","\n","epoch 0/100 return: -95.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -94.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -94.0\n","epoch 60/100 return: -189.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -98.0\n","###############    Reward for test environment for run 15: -84.53.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.942\n","ALL RESULTS TRAIL: [-83.942]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"VK4rNzyeldIv"},"execution_count":null,"outputs":[]}]}