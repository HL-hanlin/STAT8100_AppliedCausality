{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CCIL_Apr22_cartpole.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXttaQe-507l","executionInfo":{"status":"ok","timestamp":1650786417221,"user_tz":240,"elapsed":21865,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"560c57fd-117c-4246-bf1b-30baea48a822"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import os\n","\n","import torch\n","os.chdir('/content/drive/MyDrive/ImitationLearning/Invariant-Causal-Imitation-Learning-main/')\n"]},{"cell_type":"markdown","source":["# load"],"metadata":{"id":"CMy2nIGPEiAs"}},{"cell_type":"code","source":["!pip install mpi4py \n","!pip install box2d-py\n","!pip install box2d \n","!pip3 install gym[Box_2D] \n","!pip install gym==0.17.2 -qqq\n","!pip install numpy~=1.18.2 -qqq\n","!pip install pandas~=1.0.4 -qqq\n","!pip install PyYAML~=5.4.1 -qqq\n","!pip install scikit-learn~=0.22.2 -qqq\n","!pip install scipy~=1.1.0 -qqq\n","!pip install stable-baselines~=2.10.1 -qqq\n","!pip install tensorflow~=1.15.0 -qqq\n","!pip install torch>=1.6.0 -qqq\n","!pip install tqdm~=4.32.1 -qqq\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhOh_Fj16Eow","executionInfo":{"status":"ok","timestamp":1650786557566,"user_tz":240,"elapsed":140350,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"c5e2883a-7ee2-4c74-ecff-c7ff09d395e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n","\u001b[?25l\r\u001b[K     |▏                               | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |▎                               | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 30 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 40 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 51 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 61 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 71 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 81 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 112 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 122 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 133 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 143 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 153 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 163 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 174 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 184 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 194 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 204 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 215 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 225 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 235 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 245 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 256 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 266 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 276 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 286 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 296 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 307 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 317 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 327 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 337 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 348 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 358 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 368 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 378 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 389 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 399 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 409 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 419 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 430 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 440 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 450 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 460 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 471 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 481 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 491 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 501 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 512 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 522 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 532 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 542 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 552 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 563 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 573 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 583 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 593 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 604 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 614 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 624 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 634 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 645 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 655 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 665 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 675 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 686 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 696 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 706 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 716 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 727 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 737 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 747 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 757 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 768 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 778 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 788 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 798 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 808 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 819 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 829 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 839 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 849 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 860 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 870 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 880 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 890 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 901 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 911 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 921 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 931 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 942 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 952 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 962 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 972 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 983 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 993 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.6 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.7 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.8 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.9 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.3 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.4 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5 MB 4.6 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185307 sha256=704cfb823908446a273628a311115860409556da2caf4db978c289e0e9973212\n","  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.3\n","Collecting box2d-py\n","  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 8.1 MB/s \n","\u001b[?25hInstalling collected packages: box2d-py\n","Successfully installed box2d-py-2.3.8\n","Collecting box2d\n","  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 7.4 MB/s \n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.6)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n","\u001b[K     |████████████████████████████████| 1.6 MB 9.9 MB/s \n","\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.1 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n","jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 10.1 MB 9.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.5 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 636 kB 10.0 MB/s \n","\u001b[K     |████████████████████████████████| 7.1 MB 8.3 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 31.2 MB 1.3 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.4 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 240 kB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 110.5 MB 1.3 kB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 51.5 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 49.2 MB/s \n","\u001b[K     |████████████████████████████████| 503 kB 63.8 MB/s \n","\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 50 kB 4.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.32.2 which is incompatible.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.32.2 which is incompatible.\n","fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.32.2 which is incompatible.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["#config"],"metadata":{"id":"UoOvpQGcfM2h"}},{"cell_type":"code","source":["\n","config = {\n","    \"ENV\": \"CartPole-v1\",\n","    \"ALG\": \"BCIRMStudent_Apr17\",\n","    \"NUM_TRAJS_GIVEN\": 20, #\n","    \"NUM_TRAINING_ENVS\": 2,\n","    \"NOISE_DIM\": 4,\n","    \"REP_SIZE\": 16,\n","    \"TRAJ_SHIFT\": 20, # 20,\n","    \"SAMPLING_RATE\": 5,\n","    \"NUM_STEPS_TRAIN\": 10000,\n","    \"NUM_TRAJS_VALID\": 100,\n","    \"NUM_REPETITIONS\": 15,\n","    \"BATCH_SIZE\": 64,\n","    \"MLP_WIDTHS\": 64,\n","    \"ADAM_ALPHA\": 1e-3,\n","    \"SGLD_BUFFER_SIZE\": 10000,\n","    \"SGLD_LEARN_RATE\": 0.01,\n","    \"SGLD_NOISE_COEF\": 0.01,\n","    \"SGLD_NUM_STEPS\": 100,\n","    \"SGLD_REINIT_FREQ\": 0.05,\n","    \"NUM_STEPS_TRAIN_ENERGY_MODEL\": 1000,\n","    #\"NUM_STEPS_TRAIN_VAE_MODEL\": 20000,\n","    'TRIAL': 0\n","}\n","\n","\n","#config['ENV'] = \"LunarLander-v2\"\n","config['ENV'] = \"CartPole-v1\"\n","\n","#config['METHOD'] = \"BCIRM\"\n","config['METHOD'] = \"CCIL\"\n","\n","\n","\n","\n","if config['ENV'] == \"CartPole-v1\":\n","    config[\"REP_SIZE\"] = 16\n","\n","\n","\n","if config['METHOD'] == 'BCIRM':\n","    config['l2_regularizer_weight'] = 0.001\n","    config['penalty_weight'] = 10000\n","    config['penalty_anneal_iters'] = 2500\n","elif config['METHOD'] == \"iVAE_IRM\":\n","    config[\"NUM_STEPS_TRAIN_VAE_MODEL\"] = 10000\n","    config['PHASE2_SAMPLES'] = 50000\n","    #config['LATENT_DIM'] = config[\"REP_SIZE\"]\n","elif config['METHOD'] == \"CCIL\":\n","    #config['LATENT_DIM'] = config[\"REP_SIZE\"]\n","    config['MASK_PROB'] = 0.3\n","    #config['BATCH_SIZE'] = 5000\n"],"metadata":{"id":"4qkwWpjMfNzN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#testing/il"],"metadata":{"id":"tXRGSCjZfbnX"}},{"cell_type":"code","source":["import argparse\n","import os\n","import pickle\n","\n","import gym\n","import numpy as np\n","import pandas as pd\n","import yaml\n","import numpy as np\n","\n","from testing.paths import get_model_path, get_trajs_path  # pylint: disable=reimported\n","\n","from contrib.energy_model import EnergyModel\n","from contrib.env_wrapper import EnvWrapper, get_test_mult_factors\n","from network import EnvDiscriminator\n","from network import FeaturesDecoder\n","from network import FeaturesEncoder\n","from network import MineNetwork \n","from network import ObservationsDecoder\n","from network import StudentNetwork\n","\n","\n","from student import ICILStudent, BCStudent, BCIRMStudent, iVAE_IRMStudent, CCILStudent \n","from testing.train_utils import fill_buffer, make_agent, save_results\n","from vae.ivae_wrapper import VAE_wrapper\n","  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqnTIvivg1DT","executionInfo":{"status":"ok","timestamp":1650786684118,"user_tz":240,"elapsed":17132,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"089e3a45-570a-4562-a50c-ec02388406f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n","  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"]}]},{"cell_type":"markdown","source":["# make student"],"metadata":{"id":"hsMME-Bm3oMT"}},{"cell_type":"code","source":["\n","\n","# pylint: disable=redefined-outer-name\n","def make_student(run_seed, config):\n","    env = gym.make(config[\"ENV\"])\n","    trajs_path = get_trajs_path(config[\"ENV\"], \"student_\" + config[\"ALG\"], env_id=\"student\", run_seed=run_seed)\n","    model_path = get_model_path(config[\"ENV\"], \"student_\" + config[\"ALG\"], run_seed=run_seed)\n","\n","    state_dim = env.observation_space.shape[0] + config[\"NOISE_DIM\"]\n","    action_dim = env.action_space.n\n","    num_training_envs = config[\"NUM_TRAINING_ENVS\"]\n","\n","    # run_seed = run_seed\n","    batch_size = config[\"BATCH_SIZE\"]\n","    teacher = make_agent(config[\"ENV\"], config[\"EXPERT_ALG\"], config[\"NUM_TRAINING_ENVS\"])\n","    teacher.load_pretrained()\n","\n","    buffer = fill_buffer(\n","        trajs_path=teacher.trajs_paths,\n","        batch_size=batch_size,\n","        run_seed=run_seed,\n","        traj_shift=config[\"TRAJ_SHIFT\"],\n","        buffer_size_in_trajs=config[\"NUM_TRAJS_GIVEN\"],\n","        sampling_rate=config[\"SAMPLING_RATE\"],\n","        strictly_batch_data = False\n","    )\n","\n","    if buffer.total_size < batch_size:\n","        batch_size = buffer.total_size\n","\n","\n","\n","    ##########################      COMMON      ##########################\n","\n","    print(\"state_dim\", state_dim)\n","\n","    causal_features_encoder = FeaturesEncoder(\n","        input_size=state_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"]\n","    )\n","\n","    policy_network = StudentNetwork(in_dim=config[\"REP_SIZE\"], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","\n","    #print(\"config method = \", config['METHOD'])\n","\n","\n","    ##########################       BC       #######################\n","\n","    if config['METHOD'] == 'BC':\n","\n","        return BCStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","    ##########################       BC IRM       #######################\n","\n","\n","    elif config['METHOD'] == 'BCIRM':\n","\n","        return BCIRMStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","\n","    ##########################       CCIL       #######################\n","\n","\n","    elif config['METHOD'] == 'CCIL':\n","        \n","        causal_features_encoder = FeaturesEncoder(input_size=state_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","\n","        return CCILStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","    ##########################       iVAE IRM       #######################\n","\n","    elif config['METHOD'] == 'iVAE_IRM':\n","\n","        config['LATENT_DIM'] = state_dim \n","\n","        vae_wrapper =  VAE_wrapper(buffer, data_dim = state_dim, action_dim = action_dim, env_dim = config['NUM_TRAINING_ENVS'], latent_dim = config['LATENT_DIM'], use_e = True)\n","        vae_wrapper.train(num_updates=config[\"NUM_STEPS_TRAIN_VAE_MODEL\"])\n","        #vae_wrapper.start_phase2(n_samples = config['PHASE2_SAMPLES'])\n","        vae_wrapper.pa_list = [0,1,2,3,4,5,6,7]\n","        \n","\n","        causal_features_encoder = FeaturesEncoder(\n","            input_size=config[\"LATENT_DIM\"], representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"] )\n","\n","        policy_network = StudentNetwork(in_dim=config[\"REP_SIZE\"], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","\n","        phase3_obs_to_latent_encoder = FeaturesEncoder(\n","            input_size=state_dim, representation_size=config[\"LATENT_DIM\"], width=config[\"MLP_WIDTHS\"] )\n","        \n","        #causal_features_encoder = FeaturesEncoder(\n","        #            input_size=state_dim, representation_size = len(vae_wrapper.pa_list), width=config[\"MLP_WIDTHS\"])\n","\n","        #policy_network = StudentNetwork(in_dim = config['LATENT_DIM'], out_dim=action_dim, width=config[\"MLP_WIDTHS\"])\n","\n","        \n","        return iVAE_IRMStudent(\n","            env=env,\n","            vae_wrapper = vae_wrapper,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            phase3_obs_to_latent_encoder = phase3_obs_to_latent_encoder,\n","            causal_features_encoder=causal_features_encoder,\n","            policy_network=policy_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","        \n","\n","\n","    ##########################       ICIL        #######################\n","\n","    elif config['METHOD'] == 'ICIL':\n","        energy_model = EnergyModel(\n","            in_dim=state_dim,\n","            width=config[\"MLP_WIDTHS\"],\n","            batch_size=batch_size,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            buffer=buffer,\n","            sgld_buffer_size=config[\"SGLD_BUFFER_SIZE\"],\n","            sgld_learn_rate=config[\"SGLD_LEARN_RATE\"],\n","            sgld_noise_coef=config[\"SGLD_NOISE_COEF\"],\n","            sgld_num_steps=config[\"SGLD_NUM_STEPS\"],\n","            sgld_reinit_freq=config[\"SGLD_REINIT_FREQ\"],\n","        )\n","        energy_model.train(num_updates=config[\"NUM_STEPS_TRAIN_ENERGY_MODEL\"])\n","\n","        causal_features_decoder = FeaturesDecoder(action_size=action_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","\n","        observations_decoder = ObservationsDecoder(representation_size=config[\"REP_SIZE\"], out_size=state_dim, width=config[\"MLP_WIDTHS\"] )\n","\n","        env_discriminator = EnvDiscriminator(representation_size=config[\"REP_SIZE\"], num_envs=config[\"NUM_TRAINING_ENVS\"], width=config[\"MLP_WIDTHS\"])\n","\n","        noise_features_encoders = [FeaturesEncoder(input_size=state_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])  \n","            for i in range(num_training_envs)]\n","        \n","        noise_features_decoders = [FeaturesDecoder(action_size=action_dim, representation_size=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","            for i in range(num_training_envs)]\n","\n","        mine_network = MineNetwork(x_dim=config[\"REP_SIZE\"], z_dim=config[\"REP_SIZE\"], width=config[\"MLP_WIDTHS\"])\n","\n","        return ICILStudent(\n","            env=env,\n","            trajs_paths=trajs_path,\n","            model_path=model_path,\n","            num_training_envs=num_training_envs,\n","            teacher=teacher,\n","            causal_features_encoder=causal_features_encoder,\n","            noise_features_encoders=noise_features_encoders,\n","            causal_features_decoder=causal_features_decoder,\n","            noise_features_decoders=noise_features_decoders,\n","            observations_decoder=observations_decoder,\n","            env_discriminator=env_discriminator,\n","            policy_network=policy_network,\n","            energy_model=energy_model,\n","            mine_network=mine_network,\n","            buffer=buffer,\n","            adam_alpha=config[\"ADAM_ALPHA\"],\n","            config = config\n","        )\n","\n","\n","def init_arg():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--env_name\", default=\"CartPole-v1\")\n","    parser.add_argument(\"--num_trajectories\", default=20, type=int)\n","    parser.add_argument(\"--trial\", default=0, type=int)\n","    return parser.parse_args()\n"],"metadata":{"id":"BYsHrHrlffKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rKRfOUTUCciv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- CCIL -- cartpole"],"metadata":{"id":"tkcl8F5lCc0u"}},{"cell_type":"code","source":["config['MASK_PROB'] = 0.5\n","config['NUM_STEPS_TRAIN'] = 100000\n","config['ADAM_ALPHA'] = 0.001\n","config['NUM_REPETITIONS'] = 10\n","config['ENV'] = 'CartPole-v1'"],"metadata":{"id":"_yWZIYTOExhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config['METHOD'] = \"CCIL\"\n","\n","for traj_num in [1, 2, 5, 10, 20, 30, 40, 50]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","    config['ALG'] = \"FINAL_Apr24_CCILStudent_origindata_multiply_trajnum\" + str(traj_num)\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCIRMStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BCIRM\"\n","    #config['METHOD'] = \"ICIL\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 50\n","    #config[\"TRAJ_SHIFT\"] = 50\n","    #config['ENV'] == \"CartPole-v1\"\n","    ###############.  settings   ###############\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","\n","            env_wrapper_out_of_sample.noise = 0\n","\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e39d1cd3-9842-4968-c07a-12f5f2d7836d","id":"BJ20eYbwCc0v"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Config: {'ENV': 'CartPole-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum1', 'NUM_TRAJS_GIVEN': 1, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 1, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  CartPole-v1\n","Run 1 out of 10\n","state_dim 8\n","epoch 49000/100000, policy loss 0.2493583858013153 \t"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"dq08yZ2C6EhZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- CCIL -- acrobot * * *"],"metadata":{"id":"oraDNzHah0fl"}},{"cell_type":"code","source":["config['MASK_PROB'] = 0.5\n","config['NUM_STEPS_TRAIN'] = 100000\n","config['ADAM_ALPHA'] = 0.001\n","config['NUM_REPETITIONS'] = 10\n","config['ENV'] = \"Acrobot-v1\""],"metadata":{"id":"gAL4LjJoh0fl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config['METHOD'] = \"CCIL\"\n","\n","for traj_num in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","    config['ALG'] = \"FINAL_Apr24_CCILStudent_origindata_multiply_trajnum\" + str(traj_num)\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCIRMStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BCIRM\"\n","    #config['METHOD'] = \"ICIL\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 50\n","    #config[\"TRAJ_SHIFT\"] = 50\n","    #config['ENV'] == \"CartPole-v1\"\n","    ###############.  settings   ###############\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","\n","            env_wrapper_out_of_sample.noise = 0\n","\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"02f97b7f-0fb3-423f-c844-cee5fbecbf2d","id":"SslrdBJEh0fl","executionInfo":{"status":"ok","timestamp":1650815284491,"user_tz":240,"elapsed":27476629,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}}},"execution_count":9,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum1', 'NUM_TRAJS_GIVEN': 1, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 1, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.050731316208839417 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -81.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -101.0\n","epoch 40/100 return: -88.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -70.0\n","###############    Reward for test environment for run 1: -86.02.   ###############\n","\n","\n","Run 2 out of 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.00038851771387271583 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -126.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -89.0\n","###############    Reward for test environment for run 2: -88.19.   ###############\n","\n","\n","Run 3 out of 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.0003288359730504453 \tepoch 0/100 return: -139.0\n","epoch 10/100 return: -81.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -95.0\n","epoch 70/100 return: -75.0\n","epoch 80/100 return: -74.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 3: -79.84.   ###############\n","\n","\n","Run 4 out of 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.02637614496052265 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -83.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 4: -86.19.   ###############\n","\n","\n","Run 5 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.006026226561516523 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -219.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 5: -85.65.   ###############\n","\n","\n","Run 6 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.047051526606082916 \tepoch 0/100 return: -74.0\n","epoch 10/100 return: -94.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -84.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -79.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -84.0\n","###############    Reward for test environment for run 6: -86.57.   ###############\n","\n","\n","Run 7 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.00042233086423948407 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -109.0\n","epoch 20/100 return: -102.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -99.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -89.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 7: -84.31.   ###############\n","\n","\n","Run 8 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.02754838950932026 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -96.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -80.0\n","###############    Reward for test environment for run 8: -84.45.   ###############\n","\n","\n","Run 9 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.0031810326036065817 \tepoch 0/100 return: -73.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -107.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -86.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -94.0\n","###############    Reward for test environment for run 9: -86.52.   ###############\n","\n","\n","Run 10 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 1.2227094885020051e-05 \tepoch 0/100 return: -73.0\n","epoch 10/100 return: -87.0\n","epoch 20/100 return: -182.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -153.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -87.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 10: -85.48.   ###############\n","\n","\n","Average reward for 10 repetitions: -85.322\n","ALL RESULTS TRAIL: [-85.322]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum2', 'NUM_TRAJS_GIVEN': 2, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 2, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.04531491920351982 \tepoch 0/100 return: -133.0\n","epoch 10/100 return: -125.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -109.0\n","epoch 40/100 return: -110.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -116.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 1: -87.6.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.01945999264717102 \tepoch 0/100 return: -85.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -148.0\n","epoch 50/100 return: -99.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -100.0\n","###############    Reward for test environment for run 2: -81.52.   ###############\n","\n","\n","Run 3 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.05919729545712471 \tepoch 0/100 return: -138.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -63.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -84.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -97.0\n","epoch 90/100 return: -124.0\n","###############    Reward for test environment for run 3: -85.23.   ###############\n","\n","\n","Run 4 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.03193524852395058 \tepoch 0/100 return: -75.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -124.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 4: -81.82.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.012224282138049603 \tepoch 0/100 return: -125.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -100.0\n","epoch 40/100 return: -95.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -97.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 5: -88.31.   ###############\n","\n","\n","Run 6 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.08559826761484146 \tepoch 0/100 return: -73.0\n","epoch 10/100 return: -65.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -93.0\n","epoch 50/100 return: -500.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 6: -85.63.   ###############\n","\n","\n","Run 7 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.11353497952222824 \tepoch 0/100 return: -66.0\n","epoch 10/100 return: -123.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -65.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -82.0\n","###############    Reward for test environment for run 7: -84.06.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.05620826780796051 \tepoch 0/100 return: -65.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -70.0\n","epoch 70/100 return: -101.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 8: -82.02.   ###############\n","\n","\n","Run 9 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.001993665937334299 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -100.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 9: -84.85.   ###############\n","\n","\n","Run 10 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/.shortcut-targets-by-id/15_BhZyJSvQWMTBbzA9iHkhBymeY5HxXY/Invariant-Causal-Imitation-Learning-main/testing/train_utils.py:106: UserWarning: Buffer smaller than batch size\n","  warnings.warn(\"Buffer smaller than batch size\")\n"]},{"output_type":"stream","name":"stdout","text":["state_dim 10\n","epoch 99000/100000, policy loss 0.04966830462217331 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -141.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -69.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -108.0\n","###############    Reward for test environment for run 10: -85.08.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.61200000000001\n","ALL RESULTS TRAIL: [-84.61200000000001]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum3', 'NUM_TRAJS_GIVEN': 3, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 3, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.05776511877775192 \tepoch 0/100 return: -125.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -122.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -145.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 1: -84.85.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0923752635717392 \tepoch 0/100 return: -75.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -70.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -107.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 2: -83.35.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.16854090988636017 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -90.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -171.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -95.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -109.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 3: -83.88.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0457911342382431 \tepoch 0/100 return: -94.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -145.0\n","epoch 60/100 return: -124.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 4: -86.82.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.04241900146007538 \tepoch 0/100 return: -89.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -92.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 5: -79.96.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07382965832948685 \tepoch 0/100 return: -97.0\n","epoch 10/100 return: -81.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 6: -86.09.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.04956141114234924 \tepoch 0/100 return: -79.0\n","epoch 10/100 return: -98.0\n","epoch 20/100 return: -88.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -82.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -93.0\n","###############    Reward for test environment for run 7: -83.18.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.02627401426434517 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -101.0\n","epoch 20/100 return: -70.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 8: -81.74.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0805700346827507 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -66.0\n","epoch 20/100 return: -185.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -84.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -100.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 9: -81.74.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.16476182639598846 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -96.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -65.0\n","epoch 60/100 return: -139.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -150.0\n","###############    Reward for test environment for run 10: -83.52.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.513\n","ALL RESULTS TRAIL: [-83.513]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum4', 'NUM_TRAJS_GIVEN': 4, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 4, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07360929995775223 \tepoch 0/100 return: -96.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -70.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -81.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 1: -82.77.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0899667963385582 \tepoch 0/100 return: -64.0\n","epoch 10/100 return: -94.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -92.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -98.0\n","epoch 60/100 return: -79.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -74.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 2: -81.52.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0284141656011343 \tepoch 0/100 return: -104.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -74.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -157.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 3: -86.51.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08245307952165604 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -135.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 4: -83.38.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.03357425332069397 \tepoch 0/100 return: -69.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -93.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 5: -83.32.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07700690627098083 \tepoch 0/100 return: -80.0\n","epoch 10/100 return: -208.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -70.0\n","epoch 40/100 return: -159.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 6: -84.5.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.06769952178001404 \tepoch 0/100 return: -64.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -81.0\n","epoch 70/100 return: -83.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 7: -81.02.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07450373470783234 \tepoch 0/100 return: -89.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -83.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -75.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -90.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 8: -84.16.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.11460790783166885 \tepoch 0/100 return: -91.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -159.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -94.0\n","epoch 70/100 return: -86.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -91.0\n","###############    Reward for test environment for run 9: -87.84.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07551954686641693 \tepoch 0/100 return: -86.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -116.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 10: -83.27.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.829\n","ALL RESULTS TRAIL: [-83.829]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum5', 'NUM_TRAJS_GIVEN': 5, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 5, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0327165350317955 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -70.0\n","epoch 20/100 return: -88.0\n","epoch 30/100 return: -94.0\n","epoch 40/100 return: -82.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -98.0\n","epoch 70/100 return: -69.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -79.0\n","###############    Reward for test environment for run 1: -82.59.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.13382911682128906 \tepoch 0/100 return: -92.0\n","epoch 10/100 return: -142.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -94.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -65.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -94.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 2: -84.48.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.05022788047790527 \tepoch 0/100 return: -90.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -95.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -97.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 3: -85.2.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.17568887770175934 \tepoch 0/100 return: -85.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -91.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 4: -83.23.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.03322248160839081 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -80.0\n","epoch 40/100 return: -100.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -91.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -70.0\n","###############    Reward for test environment for run 5: -84.22.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.013469616882503033 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -74.0\n","epoch 60/100 return: -89.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 6: -88.11.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.057272590696811676 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -92.0\n","epoch 40/100 return: -86.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -93.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -86.0\n","###############    Reward for test environment for run 7: -86.25.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.12447944283485413 \tepoch 0/100 return: -69.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -90.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -105.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -139.0\n","###############    Reward for test environment for run 8: -82.95.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.05376419425010681 \tepoch 0/100 return: -79.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -65.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -92.0\n","epoch 70/100 return: -87.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -123.0\n","###############    Reward for test environment for run 9: -83.42.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08710333704948425 \tepoch 0/100 return: -78.0\n","epoch 10/100 return: -85.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -92.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -96.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -97.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 10: -82.17.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.26199999999999\n","ALL RESULTS TRAIL: [-84.26199999999999]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum6', 'NUM_TRAJS_GIVEN': 6, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 6, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.09598330408334732 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -64.0\n","epoch 60/100 return: -102.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 1: -82.89.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.15906991064548492 \tepoch 0/100 return: -73.0\n","epoch 10/100 return: -92.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -86.0\n","epoch 40/100 return: -99.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -100.0\n","###############    Reward for test environment for run 2: -84.26.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.09104389697313309 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -106.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -108.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -91.0\n","epoch 90/100 return: -75.0\n","###############    Reward for test environment for run 3: -81.53.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.2263779491186142 \tepoch 0/100 return: -81.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -144.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -76.0\n","epoch 60/100 return: -69.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -65.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 4: -83.81.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08101321011781693 \tepoch 0/100 return: -75.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -100.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -75.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 5: -82.96.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08457276225090027 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -134.0\n","epoch 50/100 return: -94.0\n","epoch 60/100 return: -84.0\n","epoch 70/100 return: -107.0\n","epoch 80/100 return: -92.0\n","epoch 90/100 return: -96.0\n","###############    Reward for test environment for run 6: -84.26.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08406327664852142 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -180.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -98.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 7: -84.04.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.05410761386156082 \tepoch 0/100 return: -86.0\n","epoch 10/100 return: -95.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -82.0\n","###############    Reward for test environment for run 8: -83.45.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1374097615480423 \tepoch 0/100 return: -80.0\n","epoch 10/100 return: -112.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -110.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 9: -82.4.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.11312797665596008 \tepoch 0/100 return: -81.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -93.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 10: -86.53.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.613\n","ALL RESULTS TRAIL: [-83.613]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum7', 'NUM_TRAJS_GIVEN': 7, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 7, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.15270867943763733 \tepoch 0/100 return: -93.0\n","epoch 10/100 return: -82.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -91.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -98.0\n","epoch 80/100 return: -90.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 1: -82.21.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.04020196944475174 \tepoch 0/100 return: -78.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -123.0\n","epoch 30/100 return: -87.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -111.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -74.0\n","###############    Reward for test environment for run 2: -82.5.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.06364742666482925 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -105.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -65.0\n","epoch 90/100 return: -89.0\n","###############    Reward for test environment for run 3: -85.33.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.04859964922070503 \tepoch 0/100 return: -79.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -74.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -92.0\n","epoch 50/100 return: -83.0\n","epoch 60/100 return: -151.0\n","epoch 70/100 return: -81.0\n","epoch 80/100 return: -96.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 4: -83.08.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.07775212824344635 \tepoch 0/100 return: -120.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -91.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -90.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -87.0\n","epoch 80/100 return: -181.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 5: -86.28.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1721002757549286 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -80.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 6: -83.46.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.046945758163928986 \tepoch 0/100 return: -81.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -66.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -98.0\n","###############    Reward for test environment for run 7: -86.99.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0753576010465622 \tepoch 0/100 return: -88.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -89.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -86.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -86.0\n","epoch 80/100 return: -144.0\n","epoch 90/100 return: -80.0\n","###############    Reward for test environment for run 8: -83.12.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.24509279429912567 \tepoch 0/100 return: -76.0\n","epoch 10/100 return: -74.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -69.0\n","epoch 90/100 return: -167.0\n","###############    Reward for test environment for run 9: -84.4.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.10215486586093903 \tepoch 0/100 return: -74.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -95.0\n","epoch 80/100 return: -98.0\n","epoch 90/100 return: -76.0\n","###############    Reward for test environment for run 10: -84.34.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.171\n","ALL RESULTS TRAIL: [-84.171]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum8', 'NUM_TRAJS_GIVEN': 8, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 8, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1498813033103943 \tepoch 0/100 return: -98.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -98.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -85.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -80.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 1: -83.17.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.13755951821804047 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -83.0\n","epoch 20/100 return: -69.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -81.0\n","epoch 50/100 return: -89.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 2: -83.34.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1516311913728714 \tepoch 0/100 return: -80.0\n","epoch 10/100 return: -83.0\n","epoch 20/100 return: -93.0\n","epoch 30/100 return: -85.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -83.0\n","epoch 90/100 return: -75.0\n","###############    Reward for test environment for run 3: -83.27.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08014728873968124 \tepoch 0/100 return: -86.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -64.0\n","epoch 30/100 return: -64.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -88.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 4: -86.02.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1634383499622345 \tepoch 0/100 return: -93.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -69.0\n","epoch 40/100 return: -74.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 5: -83.48.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0764927864074707 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -64.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 6: -80.66.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.12499798834323883 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -84.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -83.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -87.0\n","epoch 90/100 return: -93.0\n","###############    Reward for test environment for run 7: -84.77.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08177044987678528 \tepoch 0/100 return: -79.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -81.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -184.0\n","epoch 60/100 return: -108.0\n","epoch 70/100 return: -173.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -89.0\n","###############    Reward for test environment for run 8: -85.02.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08673648536205292 \tepoch 0/100 return: -78.0\n","epoch 10/100 return: -105.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -88.0\n","epoch 40/100 return: -100.0\n","epoch 50/100 return: -81.0\n","epoch 60/100 return: -76.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 9: -86.19.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.15989401936531067 \tepoch 0/100 return: -78.0\n","epoch 10/100 return: -70.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -72.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -75.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -65.0\n","###############    Reward for test environment for run 10: -82.14.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.80599999999998\n","ALL RESULTS TRAIL: [-83.80599999999998]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum9', 'NUM_TRAJS_GIVEN': 9, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 9, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.049335092306137085 \tepoch 0/100 return: -85.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -72.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 1: -84.8.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08832883089780807 \tepoch 0/100 return: -85.0\n","epoch 10/100 return: -64.0\n","epoch 20/100 return: -76.0\n","epoch 30/100 return: -99.0\n","epoch 40/100 return: -77.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -97.0\n","epoch 70/100 return: -86.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -73.0\n","###############    Reward for test environment for run 2: -81.5.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1336834579706192 \tepoch 0/100 return: -70.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -93.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -73.0\n","epoch 70/100 return: -131.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 3: -81.33.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.12360469996929169 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -81.0\n","epoch 30/100 return: -88.0\n","epoch 40/100 return: -87.0\n","epoch 50/100 return: -80.0\n","epoch 60/100 return: -96.0\n","epoch 70/100 return: -73.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -77.0\n","###############    Reward for test environment for run 4: -83.26.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.14032886922359467 \tepoch 0/100 return: -72.0\n","epoch 10/100 return: -80.0\n","epoch 20/100 return: -86.0\n","epoch 30/100 return: -79.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -73.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -84.0\n","epoch 80/100 return: -76.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 5: -81.03.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.14554496109485626 \tepoch 0/100 return: -93.0\n","epoch 10/100 return: -73.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -74.0\n","epoch 70/100 return: -95.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -69.0\n","###############    Reward for test environment for run 6: -83.83.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.0899440124630928 \tepoch 0/100 return: -74.0\n","epoch 10/100 return: -93.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -74.0\n","epoch 50/100 return: -79.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 7: -92.38.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.124188631772995 \tepoch 0/100 return: -71.0\n","epoch 10/100 return: -120.0\n","epoch 20/100 return: -92.0\n","epoch 30/100 return: -91.0\n","epoch 40/100 return: -88.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -105.0\n","epoch 90/100 return: -108.0\n","###############    Reward for test environment for run 8: -80.32.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1903323382139206 \tepoch 0/100 return: -104.0\n","epoch 10/100 return: -64.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -75.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -90.0\n","epoch 70/100 return: -95.0\n","epoch 80/100 return: -84.0\n","epoch 90/100 return: -95.0\n","###############    Reward for test environment for run 9: -85.39.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.06411013007164001 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -85.0\n","epoch 30/100 return: -71.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -78.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -99.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -98.0\n","###############    Reward for test environment for run 10: -83.24.   ###############\n","\n","\n","Average reward for 10 repetitions: -83.708\n","ALL RESULTS TRAIL: [-83.708]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum10', 'NUM_TRAJS_GIVEN': 10, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 10, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1959998905658722 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -80.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -65.0\n","epoch 70/100 return: -72.0\n","epoch 80/100 return: -86.0\n","epoch 90/100 return: -99.0\n","###############    Reward for test environment for run 1: -81.4.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1975845843553543 \tepoch 0/100 return: -93.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -90.0\n","epoch 50/100 return: -98.0\n","epoch 60/100 return: -92.0\n","epoch 70/100 return: -92.0\n","epoch 80/100 return: -89.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 2: -82.53.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.14857926964759827 \tepoch 0/100 return: -89.0\n","epoch 10/100 return: -77.0\n","epoch 20/100 return: -92.0\n","epoch 30/100 return: -74.0\n","epoch 40/100 return: -79.0\n","epoch 50/100 return: -92.0\n","epoch 60/100 return: -65.0\n","epoch 70/100 return: -74.0\n","epoch 80/100 return: -82.0\n","epoch 90/100 return: -145.0\n","###############    Reward for test environment for run 3: -91.85.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.16009850800037384 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -83.0\n","epoch 50/100 return: -205.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 4: -82.1.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.029052771627902985 \tepoch 0/100 return: -78.0\n","epoch 10/100 return: -75.0\n","epoch 20/100 return: -90.0\n","epoch 30/100 return: -78.0\n","epoch 40/100 return: -96.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -75.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 5: -82.14.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08628002554178238 \tepoch 0/100 return: -91.0\n","epoch 10/100 return: -89.0\n","epoch 20/100 return: -97.0\n","epoch 30/100 return: -89.0\n","epoch 40/100 return: -89.0\n","epoch 50/100 return: -103.0\n","epoch 60/100 return: -80.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -73.0\n","epoch 90/100 return: -90.0\n","###############    Reward for test environment for run 6: -88.13.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1192888468503952 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -72.0\n","epoch 40/100 return: -91.0\n","epoch 50/100 return: -100.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -72.0\n","###############    Reward for test environment for run 7: -86.27.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.16127891838550568 \tepoch 0/100 return: -77.0\n","epoch 10/100 return: -72.0\n","epoch 20/100 return: -73.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -86.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -70.0\n","###############    Reward for test environment for run 8: -85.62.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.17379026114940643 \tepoch 0/100 return: -152.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -94.0\n","epoch 30/100 return: -116.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -102.0\n","epoch 60/100 return: -87.0\n","epoch 70/100 return: -89.0\n","epoch 80/100 return: -71.0\n","epoch 90/100 return: -99.0\n","###############    Reward for test environment for run 9: -81.91.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.17468787729740143 \tepoch 0/100 return: -79.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -72.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -86.0\n","epoch 60/100 return: -78.0\n","epoch 70/100 return: -94.0\n","epoch 80/100 return: -80.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 10: -84.85.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.67999999999999\n","ALL RESULTS TRAIL: [-84.67999999999999]\n","Config: {'ENV': 'Acrobot-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum20', 'NUM_TRAJS_GIVEN': 20, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 20, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  Acrobot-v1\n","Run 1 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1960655301809311 \tepoch 0/100 return: -73.0\n","epoch 10/100 return: -76.0\n","epoch 20/100 return: -78.0\n","epoch 30/100 return: -100.0\n","epoch 40/100 return: -92.0\n","epoch 50/100 return: -72.0\n","epoch 60/100 return: -234.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -65.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 1: -88.15.   ###############\n","\n","\n","Run 2 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.24187220633029938 \tepoch 0/100 return: -89.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -75.0\n","epoch 30/100 return: -90.0\n","epoch 40/100 return: -85.0\n","epoch 50/100 return: -75.0\n","epoch 60/100 return: -91.0\n","epoch 70/100 return: -93.0\n","epoch 80/100 return: -148.0\n","epoch 90/100 return: -87.0\n","###############    Reward for test environment for run 2: -83.89.   ###############\n","\n","\n","Run 3 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1526719182729721 \tepoch 0/100 return: -98.0\n","epoch 10/100 return: -135.0\n","epoch 20/100 return: -87.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -69.0\n","epoch 50/100 return: -86.0\n","epoch 60/100 return: -130.0\n","epoch 70/100 return: -78.0\n","epoch 80/100 return: -75.0\n","epoch 90/100 return: -89.0\n","###############    Reward for test environment for run 3: -84.77.   ###############\n","\n","\n","Run 4 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.1046326756477356 \tepoch 0/100 return: -69.0\n","epoch 10/100 return: -88.0\n","epoch 20/100 return: -77.0\n","epoch 30/100 return: -97.0\n","epoch 40/100 return: -71.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -72.0\n","epoch 70/100 return: -76.0\n","epoch 80/100 return: -96.0\n","epoch 90/100 return: -70.0\n","###############    Reward for test environment for run 4: -82.89.   ###############\n","\n","\n","Run 5 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.16250436007976532 \tepoch 0/100 return: -80.0\n","epoch 10/100 return: -79.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -73.0\n","epoch 40/100 return: -76.0\n","epoch 50/100 return: -103.0\n","epoch 60/100 return: -85.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -85.0\n","epoch 90/100 return: -75.0\n","###############    Reward for test environment for run 5: -82.93.   ###############\n","\n","\n","Run 6 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.15926019847393036 \tepoch 0/100 return: -96.0\n","epoch 10/100 return: -81.0\n","epoch 20/100 return: -96.0\n","epoch 30/100 return: -69.0\n","epoch 40/100 return: -73.0\n","epoch 50/100 return: -88.0\n","epoch 60/100 return: -103.0\n","epoch 70/100 return: -65.0\n","epoch 80/100 return: -94.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 6: -85.38.   ###############\n","\n","\n","Run 7 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.13930417597293854 \tepoch 0/100 return: -84.0\n","epoch 10/100 return: -71.0\n","epoch 20/100 return: -79.0\n","epoch 30/100 return: -158.0\n","epoch 40/100 return: -70.0\n","epoch 50/100 return: -84.0\n","epoch 60/100 return: -164.0\n","epoch 70/100 return: -71.0\n","epoch 80/100 return: -79.0\n","epoch 90/100 return: -64.0\n","###############    Reward for test environment for run 7: -84.83.   ###############\n","\n","\n","Run 8 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.20022696256637573 \tepoch 0/100 return: -84.0\n","epoch 10/100 return: -78.0\n","epoch 20/100 return: -83.0\n","epoch 30/100 return: -76.0\n","epoch 40/100 return: -80.0\n","epoch 50/100 return: -96.0\n","epoch 60/100 return: -77.0\n","epoch 70/100 return: -77.0\n","epoch 80/100 return: -64.0\n","epoch 90/100 return: -71.0\n","###############    Reward for test environment for run 8: -84.37.   ###############\n","\n","\n","Run 9 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.08368340134620667 \tepoch 0/100 return: -87.0\n","epoch 10/100 return: -91.0\n","epoch 20/100 return: -71.0\n","epoch 30/100 return: -77.0\n","epoch 40/100 return: -64.0\n","epoch 50/100 return: -77.0\n","epoch 60/100 return: -88.0\n","epoch 70/100 return: -85.0\n","epoch 80/100 return: -78.0\n","epoch 90/100 return: -85.0\n","###############    Reward for test environment for run 9: -83.29.   ###############\n","\n","\n","Run 10 out of 10\n","state_dim 10\n","epoch 99000/100000, policy loss 0.18500438332557678 \tepoch 0/100 return: -85.0\n","epoch 10/100 return: -86.0\n","epoch 20/100 return: -84.0\n","epoch 30/100 return: -82.0\n","epoch 40/100 return: -78.0\n","epoch 50/100 return: -71.0\n","epoch 60/100 return: -71.0\n","epoch 70/100 return: -155.0\n","epoch 80/100 return: -77.0\n","epoch 90/100 return: -78.0\n","###############    Reward for test environment for run 10: -86.52.   ###############\n","\n","\n","Average reward for 10 repetitions: -84.702\n","ALL RESULTS TRAIL: [-84.702]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jT1UWt646AK9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 Trails -- CCIL -- lunarlander"],"metadata":{"id":"S80hq3a2h1Nt"}},{"cell_type":"code","source":["config['MASK_PROB'] = 0.5\n","config['NUM_STEPS_TRAIN'] = 100000\n","config['ADAM_ALPHA'] = 0.001\n","config['NUM_REPETITIONS'] = 10\n","config['ENV'] = 'LunarLander-v2'"],"metadata":{"id":"MNB_ZtF0h1Nt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config['METHOD'] = \"CCIL\"\n","\n","for traj_num in [2, 4, 8, 16, 32, 64, 128]:\n","    config[\"NUM_TRAJS_GIVEN\"] = traj_num\n","    config[\"TRAJ_SHIFT\"] = traj_num\n","\n","    config['ALG'] = \"FINAL_Apr24_CCILStudent_origindata_multiply_trajnum\" + str(traj_num)\n","\n","\n","    ###############.  settings   ###############\n","    #config['ALG'] = \"BCIRMStudent_Apr19_replicatedata\"\n","    #config['METHOD'] = \"BCIRM\"\n","    #config['METHOD'] = \"ICIL\"\n","    #config[\"NUM_TRAJS_GIVEN\"] = 50\n","    #config[\"TRAJ_SHIFT\"] = 50\n","    #config['ENV'] == \"CartPole-v1\"\n","    ###############.  settings   ###############\n","\n","    all_results_trail = []\n","\n","    for trail in range(1): \n","        config['TRIAL'] = trail \n","\n","\n","        ###############.  start a trail   ###############\n","\n","        config[\"EXPERT_ALG\"] = yaml.load(open(\"testing/config.yml\"), Loader=yaml.FullLoader)[config[\"ENV\"]]\n","        print(\"Config: %s\" % config)\n","\n","        TRIAL = config[\"TRIAL\"] #args.trial\n","        print(\"Trial number %s\" % TRIAL)\n","\n","        results_dir_base = \"testing/results/\"\n","        results_dir = os.path.join(results_dir_base, config[\"ENV\"], str(config[\"NUM_TRAJS_GIVEN\"]), config[\"ALG\"])\n","\n","        if not os.path.exists(results_dir):\n","            os.makedirs(results_dir)\n","\n","        config_file = \"trial_\" + str(TRIAL) + \"_\" + \"config.pkl\"\n","\n","        results_file_name = \"trial_\" + str(TRIAL) + \"_\" + \"results.csv\"\n","        results_file_path = os.path.join(results_dir, results_file_name)\n","\n","        if os.path.exists(os.path.join(results_dir, config_file)):\n","            raise NameError(\"CONFIG file already exists %s. Choose a different trial number.\" % config_file)\n","        pickle.dump(config, open(os.path.join(results_dir, config_file), \"wb\"))\n","\n","\n","\n","\n","        ###############.  10 runs for each trail   ###############\n","\n","        print(\"config method = \", config['METHOD'])\n","        print(\"config env = \", config['ENV'])\n","\n","        for run_seed in range(config[\"NUM_REPETITIONS\"]):\n","            print(\"Run %s out of %s\" % (run_seed + 1, config[\"NUM_REPETITIONS\"]))\n","            student = make_student(run_seed, config)\n","            student.train(num_updates=config[\"NUM_STEPS_TRAIN\"])\n","\n","            env_wrapper_out_of_sample = EnvWrapper(\n","                env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n","            )\n","\n","            env_wrapper_out_of_sample.noise = 0\n","\n","            action_match, return_mean, return_std = student.test(\n","                num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n","            )\n","\n","            result = (action_match, return_mean, return_std)\n","            print(\"###############    Reward for test environment for run %s: %s.   ###############\\n\\n\" % (run_seed + 1, return_mean))\n","            save_results(results_file_path, run_seed, action_match, return_mean, return_std)\n","\n","        results_trial = pd.read_csv(\n","            \"testing/results/\"\n","            + config[\"ENV\"]\n","            + \"/\"\n","            + str(config[\"NUM_TRAJS_GIVEN\"])\n","            + \"/\"\n","            + config[\"ALG\"]\n","            + \"/trial_\"\n","            + str(TRIAL)\n","            + \"_results.csv\",\n","            header=None,\n","        )\n","\n","        print(\"Average reward for 10 repetitions: %s\" % np.mean(results_trial[2].values))\n","\n","        all_results_trail.append(np.mean(results_trial[2].values))\n","    print(\"ALL RESULTS TRAIL:\" , all_results_trail)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e39d1cd3-9842-4968-c07a-12f5f2d7836d","id":"tbiWvnsOh1Nt"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Config: {'ENV': 'CartPole-v1', 'ALG': 'FINAL_Apr24_CCILStudent_origindata_multiply_trajnum1', 'NUM_TRAJS_GIVEN': 1, 'NUM_TRAINING_ENVS': 2, 'NOISE_DIM': 4, 'REP_SIZE': 16, 'TRAJ_SHIFT': 1, 'SAMPLING_RATE': 5, 'NUM_STEPS_TRAIN': 100000, 'NUM_TRAJS_VALID': 100, 'NUM_REPETITIONS': 10, 'BATCH_SIZE': 64, 'MLP_WIDTHS': 64, 'ADAM_ALPHA': 0.001, 'SGLD_BUFFER_SIZE': 10000, 'SGLD_LEARN_RATE': 0.01, 'SGLD_NOISE_COEF': 0.01, 'SGLD_NUM_STEPS': 100, 'SGLD_REINIT_FREQ': 0.05, 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000, 'TRIAL': 0, 'METHOD': 'CCIL', 'MASK_PROB': 0.5, 'EXPERT_ALG': 'dqn'}\n","Trial number 0\n","config method =  CCIL\n","config env =  CartPole-v1\n","Run 1 out of 10\n","state_dim 8\n","epoch 2000/100000, policy loss 0.5670180916786194 \t"]}]},{"cell_type":"markdown","source":["#trash"],"metadata":{"id":"-gldLOvJhYXC"}},{"cell_type":"code","source":["\n","def _compute_loss(samples):\n","    state = torch.FloatTensor(samples[\"state\"]).to(self.device)\n","    action = torch.LongTensor(samples[\"action\"]).to(self.device)\n","    #next_state = torch.FloatTensor(samples[\"next_state\"]).to(self.device)\n","    #env_ids = torch.LongTensor(samples[\"env\"]).to(self.device)\n","    \n","            \n","    prob = torch.ones(state.size()) * (1 - self.mask_prob)\n","    \n","    mask = torch.bernoulli(prob).to(self.device)\n","    state_concat = torch.cat([state * mask, mask], dim=1)\n","\n","    causal_rep = self.causal_features_encoder(state_concat)  # need this encoder: S -> rep\n","\n","    # 1. Policy loss\n","    qvalues = self.policy_network(causal_rep) # need this encoder:  rep -> A\n","    ce_loss = nn.CrossEntropyLoss()(qvalues, action)\n","\n","    return ce_loss, mask\n"],"metadata":{"id":"LeQCHJRPL9Ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","num_masks = 100000\n","best_mask = None\n","best_loss = np.inf\n","\n","self = student \n","\n","\n","for i in range(num_masks): \n","    sample = self.buffer.sample()\n","    ce_loss, curr_mask = _compute_loss(sample)\n","    if ce_loss < best_loss:\n","        best_mask = curr_mask\n","        print(ce_loss)\n","        best_loss = ce_loss\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWN64U1xLhsa","executionInfo":{"status":"ok","timestamp":1650780879590,"user_tz":240,"elapsed":131399,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"b0102539-a384-4ee6-96b3-a09194a73136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.4874, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4773, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"code","source":["state = sample['state'] \n","prob = torch.ones(state.shape[1]) * (1 - self.mask_prob)\n","mask = torch.bernoulli(prob).to(self.device)\n","mask = torch.tile(mask, (state.shape[0],1))\n","state_concat = torch.cat([state * mask, mask], dim=1)\n","causal_rep = self.causal_features_encoder(state_concat)  # need this encoder: S -> rep\n","\n","# 1. Policy loss\n","qvalues = self.policy_network(causal_rep) # need this encoder:  rep -> A\n","ce_loss = nn.CrossEntropyLoss()(qvalues, action)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUIVAlvyMLu9","executionInfo":{"status":"ok","timestamp":1650781048862,"user_tz":240,"elapsed":270,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"496e78ff-1e0c-4ca1-f915-530ca99590b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.,  ..., 1., 0., 1.],\n","        [0., 0., 0.,  ..., 1., 0., 1.],\n","        [0., 0., 0.,  ..., 1., 0., 1.],\n","        ...,\n","        [0., 0., 0.,  ..., 1., 0., 1.],\n","        [0., 0., 0.,  ..., 1., 0., 1.],\n","        [0., 0., 0.,  ..., 1., 0., 1.]], device='cuda:0')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["student.best_mask[0,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xG0QKGYLPJ2i","executionInfo":{"status":"ok","timestamp":1650783581480,"user_tz":240,"elapsed":339,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"f2780d24-ec29-43e2-e903-18e4a8bce0a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 0., 0., 0., 0., 1., 1., 1.], device='cuda:0')"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["env_wrapper_out_of_sample = EnvWrapper(\n","    env=gym.make(config[\"ENV\"]), mult_factor=get_test_mult_factors(config['NOISE_DIM'] - 1), idx=3, seed=1\n",")\n","\n","env_wrapper_out_of_sample.noise = 0\n","\n","action_match, return_mean, return_std = student.test(\n","    num_episodes=config[\"NUM_TRAJS_VALID\"], env_wrapper=env_wrapper_out_of_sample\n",")\n","\n","result = (action_match, return_mean, return_std)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbgjeWKCQeGQ","executionInfo":{"status":"ok","timestamp":1650784004740,"user_tz":240,"elapsed":1285,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"55ae5995-8ad5-455b-ea28-b602635d1357"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0/100 return: 10.0\n","epoch 10/100 return: 10.0\n","epoch 20/100 return: 9.0\n","epoch 30/100 return: 9.0\n","epoch 40/100 return: 8.0\n","epoch 50/100 return: 9.0\n","epoch 60/100 return: 10.0\n","epoch 70/100 return: 9.0\n","epoch 80/100 return: 10.0\n","epoch 90/100 return: 10.0\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.0, 9.36, 0.7282856582413249)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["student.buffer.total_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypa0Wl-aVQmf","executionInfo":{"status":"ok","timestamp":1650783097144,"user_tz":240,"elapsed":249,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"4707a8b2-7000-4dff-d93b-968e059dd18a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["498000"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMBNn4cbhKWe","executionInfo":{"status":"ok","timestamp":1650786087423,"user_tz":240,"elapsed":299,"user":{"displayName":"2 Lin","userId":"15119774230930098070"}},"outputId":"ee7bc44f-f36f-4c75-ee4d-ed290a093b05"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ADAM_ALPHA': 0.001,\n"," 'ALG': 'BCIRMStudent_Apr17',\n"," 'BATCH_SIZE': 64,\n"," 'ENV': 'CartPole-v1',\n"," 'MASK_PROB': 0.5,\n"," 'METHOD': 'CCIL',\n"," 'MLP_WIDTHS': 64,\n"," 'NOISE_DIM': 4,\n"," 'NUM_REPETITIONS': 15,\n"," 'NUM_STEPS_TRAIN': 100000,\n"," 'NUM_STEPS_TRAIN_ENERGY_MODEL': 1000,\n"," 'NUM_TRAINING_ENVS': 2,\n"," 'NUM_TRAJS_GIVEN': 20,\n"," 'NUM_TRAJS_VALID': 100,\n"," 'REP_SIZE': 16,\n"," 'SAMPLING_RATE': 5,\n"," 'SGLD_BUFFER_SIZE': 10000,\n"," 'SGLD_LEARN_RATE': 0.01,\n"," 'SGLD_NOISE_COEF': 0.01,\n"," 'SGLD_NUM_STEPS': 100,\n"," 'SGLD_REINIT_FREQ': 0.05,\n"," 'TRAJ_SHIFT': 20,\n"," 'TRIAL': 0}"]},"metadata":{},"execution_count":8}]}]}